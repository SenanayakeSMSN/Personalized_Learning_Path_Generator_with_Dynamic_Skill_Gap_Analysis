{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c001674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB Atlas connection\n",
    "def connect_to_mongodb():\n",
    "    connection_string = os.getenv(\"mongodb+srv://shashi:VSXV9WDNmRvYnA7p@clusterskillgapanalysis.vnbcnju.mongodb.net/\")  # e.g., mongodb+srv://<user>:<pass>@ac-bxzq58b.vnbcnju.mongodb.net/<dbname>?retryWrites=true&w=majority\n",
    "    client = MongoClient(connection_string)\n",
    "    db = client[\"skillgapanalysis\"]  # Replace with your database name\n",
    "    return db[\"jobrole_skill\"]  # Replace with your collection name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd56f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (11.0.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Using cached pypdfium2-4.30.1-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.4.0)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250327->pdfplumber)\n",
      "  Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/5.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/5.6 MB 2.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 1.3/5.6 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.1/5.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.6/5.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.4/5.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.5/5.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 3.3 MB/s eta 0:00:00\n",
      "Using cached pypdfium2-4.30.1-py3-none-win_amd64.whl (3.0 MB)\n",
      "Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.0/3.2 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.1/3.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 5.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdfium2, cryptography, pdfminer.six, pdfplumber\n",
      "Successfully installed cryptography-44.0.2 pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d51bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_cv_text(cv_path):\n",
    "    \"\"\"Extract text from a CV PDF.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(cv_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                text += (page.extract_text() or \"\") + \"\\n\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading CV: {str(e)}\")\n",
    "\n",
    "def extract_skills_section(cv_text):\n",
    "    \"\"\"Extract the 'Skills' section from CV text.\"\"\"\n",
    "    lines = cv_text.split(\"\\n\")\n",
    "    skills_section = []\n",
    "    in_skills_section = False\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.lower().startswith(\"skills\"):\n",
    "            in_skills_section = True\n",
    "            continue\n",
    "        if in_skills_section:\n",
    "            if line.strip() == \"\" or line.lower().startswith((\"experience\", \"education\")):\n",
    "                in_skills_section = False\n",
    "            else:\n",
    "                skills_section.append(line.strip())\n",
    "    \n",
    "    skills_text = \" \".join(skills_section)\n",
    "    return skills_text if skills_text else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff64681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=os.getenv(\"AIzaSyBvRnSojVCuojgtGI7RisnW6-S4VpBYJWo\"))\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "def extract_skills_with_gemini(skills_text):\n",
    "    \"\"\"Use Gemini to extract skills from the skills section text.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a skill extraction assistant. Given the following text from a CV's 'Skills' section, extract the skills and return them as a JSON array. Ensure skills are clean, distinct, and properly formatted (e.g., capitalize 'PyTorch', 'AWS SageMaker'). Combine similar skills (e.g., 'ML' and 'Machine Learning' as 'Machine Learning').\n",
    "\n",
    "    Text: {skills_text}\n",
    "\n",
    "    Output format:\n",
    "    ```json\n",
    "    [\"Skill1\", \"Skill2\", ...]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba155d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_required_skills(job_collection, job_role):\n",
    "    \"\"\"Retrieve and parse required skills for the job role from MongoDB Atlas.\"\"\"\n",
    "    job_doc = job_collection.find_one({\"Job_Role\": job_role})\n",
    "    if not job_doc:\n",
    "        raise ValueError(f\"Job role '{job_role}' not found in database\")\n",
    "    \n",
    "    # Parse comma-separated skills\n",
    "    required_skills = [skill.strip() for skill in job_doc[\"Required_Skills\"].split(\",\")]\n",
    "    return required_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df8d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_gap_analysis(cv_skills, required_skills):\n",
    "    \"\"\"Identify missing skills by comparing CV skills with required skills.\"\"\"\n",
    "    cv_skills_set = set(skill.lower() for skill in cv_skills)\n",
    "    required_skills_set = set(skill.lower() for skill in required_skills)\n",
    "    \n",
    "    # Missing skills: required skills not in CV\n",
    "    missing_skills = required_skills_set - cv_skills_set\n",
    "    \n",
    "    # Return original case for display\n",
    "    return [skill for skill in required_skills if skill.lower() in missing_skills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "186eae52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Failed to extract skills from CV'}\n"
     ]
    }
   ],
   "source": [
    "def analyze_cv_skill_gap(cv_path, dream_job_role):\n",
    "    \"\"\"Analyze skill gap for a CV and dream job role using MongoDB Atlas.\"\"\"\n",
    "    try:\n",
    "        # Step 1: Connect to MongoDB Atlas\n",
    "        job_collection = connect_to_mongodb()\n",
    "        \n",
    "        # Step 2: Extract CV text\n",
    "        cv_text = extract_cv_text(cv_path)\n",
    "        \n",
    "        # Step 3: Extract skills section\n",
    "        skills_text = extract_skills_section(cv_text)\n",
    "        if not skills_text:\n",
    "            return {\"error\": \"No skills section found in CV\"}\n",
    "        \n",
    "        # Step 4: Extract skills using Gemini\n",
    "        cv_skills = extract_skills_with_gemini(skills_text)\n",
    "        if not cv_skills:\n",
    "            return {\"error\": \"Failed to extract skills from CV\"}\n",
    "        \n",
    "        # Step 5: Get required skills from MongoDB\n",
    "        required_skills = get_required_skills(job_collection, dream_job_role)\n",
    "        \n",
    "        # Step 6: Perform skill gap analysis\n",
    "        missing_skills = skill_gap_analysis(cv_skills, required_skills)\n",
    "        \n",
    "        # Step 7: Return results\n",
    "        return {\n",
    "            \"job_role\": dream_job_role,\n",
    "            \"cv_skills\": cv_skills,\n",
    "            \"required_skills\": required_skills,\n",
    "            \"missing_skills\": missing_skills\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Example usage\n",
    "cv_path = r\"C:\\Users\\shash\\Downloads\\data-scientist-resume-example.pdf\"\n",
    "dream_job_role = \"Insurance Data Analyst\"\n",
    "result = analyze_cv_skill_gap(cv_path, dream_job_role)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0dcac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d1e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5bb69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58cdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385155b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc61c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "##________________________(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7160d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.11.6)\n",
      "Requirement already satisfied: pymongo in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.12.0)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: dnspython in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0)\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (11.0.0)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (20250327)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (44.0.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.166.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (5.29.2)\n",
      "Requirement already satisfied: pydantic in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.10.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shash\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\shash\\appdata\\roaming\\python\\python310\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\shash\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber pymongo google-generativeai python-dotenv dnspython pytesseract Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f3d1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Libraries and Setup\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Setup logging to debug issues\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Hardcode credentials (no .env)\n",
    "GOOGLE_API_KEY = \"AIzaSyBvRnSojVCuojgtGI7RisnW6-S4VpBYJWo\"  # Replace with your Gemini API key\n",
    "MONGODB_URI = \"mongodb+srv://shashi:VSXV9WDNmRvYnA7p@clusterskillgapanalysis.vnbcnju.mongodb.net/skillgapanalysis?retryWrites=true&w=majority\"\n",
    "\n",
    "# Import dependencies and check if installed\n",
    "try:\n",
    "    import pdfplumber\n",
    "except ImportError:\n",
    "    raise ImportError(\"pdfplumber is not installed. Run: %pip install pdfplumber\")\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except ImportError:\n",
    "    raise ImportError(\"google-generativeai is not installed. Run: %pip install google-generativeai\")\n",
    "\n",
    "try:\n",
    "    import pytesseract\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    raise ImportError(\"pytesseract or PIL is not installed. Run: %pip install pytesseract Pillow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be21c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: MongoDB Connection\n",
    "def connect_to_mongodb():\n",
    "    try:\n",
    "        client = MongoClient(MONGODB_URI)\n",
    "        db = client[\"skillgapanalysis\"]\n",
    "        collection = db[\"jobrole_skill\"]\n",
    "        collection.create_index(\"Job_Role\")\n",
    "        logging.info(\"Connected to MongoDB Atlas\")\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to connect to MongoDB: {str(e)}\")\n",
    "        raise ValueError(f\"Failed to connect to MongoDB: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b422e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Enhanced CV Text Extraction\n",
    "def extract_cv_text(cv_path):\n",
    "    try:\n",
    "        with pdfplumber.open(cv_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "                    logging.info(f\"Extracted text from page {page.page_number} using pdfplumber\")\n",
    "                else:\n",
    "                    logging.warning(f\"No text extracted from page {page.page_number}. Using OCR.\")\n",
    "                    try:\n",
    "                        img = page.to_image().original\n",
    "                        ocr_text = pytesseract.image_to_string(img)\n",
    "                        text += ocr_text + \"\\n\"\n",
    "                        logging.info(f\"Extracted OCR text from page {page.page_number}\")\n",
    "                    except Exception as ocr_e:\n",
    "                        logging.error(f\"OCR failed for page {page.page_number}: {str(ocr_e)}\")\n",
    "                        text += \"\\n\"\n",
    "            if not text.strip():\n",
    "                raise ValueError(\"No text extracted from CV. Check PDF format or Tesseract installation.\")\n",
    "            logging.info(f\"Extracted text from CV: {text[:100]}...\")\n",
    "            return text\n",
    "    except pdfplumber.pdfminer.pdfdocument.PDFPasswordIncorrect:\n",
    "        logging.error(\"PDF is password-protected. Provide the password or use an unprotected PDF.\")\n",
    "        raise ValueError(\"PDF is password-protected\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading CV: {str(e)}\")\n",
    "        raise ValueError(f\"Error reading CV: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe476521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Skills Section Extraction\n",
    "def extract_skills_section(cv_text):\n",
    "    try:\n",
    "        # Match 'Skills' and capture until next major section, but limit to skill-related text\n",
    "        match = re.search(\n",
    "            r\"(skills|technical skills|key skills):?\\s*(.*?)(?:\\n\\s*(experience|education|projects|contact|certifications|$))\",\n",
    "            cv_text, re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "        if match:\n",
    "            skills_text = match.group(2).strip()\n",
    "            # Clean up: keep only lines that look like skills (avoid project descriptions)\n",
    "            skills_lines = [line for line in skills_text.split('\\n') if any(\n",
    "                keyword in line.lower() for keyword in [\n",
    "                    'proficient', 'strong', 'skills', 'machine learning', 'python', 'statistics'\n",
    "                ]\n",
    "            ) or re.match(r'^\\s*[-•*]\\s', line)]\n",
    "            cleaned_skills = ' '.join(skills_lines).strip()\n",
    "            logging.info(f\"Extracted skills section: {cleaned_skills}\")\n",
    "            return cleaned_skills if cleaned_skills else None\n",
    "        logging.warning(\"No skills section found in CV text\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting skills section: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88eea9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Gemini Skill Extraction\n",
    "def extract_skills_with_gemini(skills_text):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = (\n",
    "            \"Extract skills from this CV Skills section: \" + skills_text +\n",
    "            \". Return a JSON array of clean, distinct skills (e.g., capitalize 'PyTorch'). \" +\n",
    "            \"Combine similar skills (e.g., 'ML' and 'Machine Learning' as 'Machine Learning'). \" +\n",
    "            \"Return [] if no skills or input is empty. Example: Input: 'Machine Learning, ML, PyTorch' \" +\n",
    "            \"Output: [\\\"Machine Learning\\\", \\\"PyTorch\\\"]\"\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        raw_response = response.text.strip()\n",
    "        logging.info(f\"Gemini raw response: {raw_response}\")\n",
    "        try:\n",
    "            skills = json.loads(raw_response)\n",
    "            if not isinstance(skills, list):\n",
    "                logging.error(\"Gemini response is not a JSON array\")\n",
    "                return []\n",
    "            logging.info(f\"Extracted skills: {skills}\")\n",
    "            return skills\n",
    "        except json.JSONDecodeError:\n",
    "            logging.error(\"Failed to parse Gemini response as JSON\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in Gemini skill extraction: {str(e)}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7610a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: MongoDB Query\n",
    "def get_required_skills(job_collection, job_role):\n",
    "    try:\n",
    "        job_doc = job_collection.find_one({\"Job_Role\": job_role})\n",
    "        if not job_doc:\n",
    "            raise ValueError(f\"Job role '{job_role}' not found in database\")\n",
    "        required_skills = [skill.strip() for skill in job_doc[\"Required_Skills\"].split(\",\")]\n",
    "        logging.info(f\"Required skills for {job_role}: {required_skills}\")\n",
    "        return required_skills\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving required skills: {str(e)}\")\n",
    "        raise ValueError(f\"Error retrieving required skills: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "106feb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Skill Gap Analysis\n",
    "def skill_gap_analysis(cv_skills, required_skills):\n",
    "    try:\n",
    "        cv_skills_set = set(skill.lower() for skill in cv_skills)\n",
    "        required_skills_set = set(skill.lower() for skill in required_skills)\n",
    "        missing_skills = required_skills_set - cv_skills_set\n",
    "        result = [skill for skill in required_skills if skill.lower() in missing_skills]\n",
    "        logging.info(f\"Missing skills: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in skill gap analysis: {str(e)}\")\n",
    "        raise ValueError(f\"Error in skill gap analysis: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "405239fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Main Analysis Function\n",
    "def analyze_cv_skill_gap(cv_path, dream_job_role):\n",
    "    try:\n",
    "        job_collection = connect_to_mongodb()\n",
    "        cv_text = extract_cv_text(cv_path)\n",
    "        skills_text = extract_skills_section(cv_text)\n",
    "        if not skills_text:\n",
    "            logging.error(\"No skills section found in CV\")\n",
    "            return {\"error\": \"No skills section found in CV. Ensure the CV has a 'Skills' section.\"}\n",
    "        cv_skills = extract_skills_with_gemini(skills_text)\n",
    "        if not cv_skills:\n",
    "            logging.error(\"Failed to extract skills from CV\")\n",
    "            return {\"error\": \"Failed to extract skills from CV. Check CV formatting, skills section content, or Gemini API response.\"}\n",
    "        required_skills = get_required_skills(job_collection, dream_job_role)\n",
    "        missing_skills = skill_gap_analysis(cv_skills, required_skills)\n",
    "        result = {\n",
    "            \"job_role\": dream_job_role,\n",
    "            \"cv_skills\": cv_skills,\n",
    "            \"required_skills\": required_skills,\n",
    "            \"missing_skills\": missing_skills\n",
    "        }\n",
    "        logging.info(f\"Skill gap analysis result: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Skill gap analysis error: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7394914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 15:05:56,414 - INFO - Gemini raw response: ```json\n",
      "[\n",
      "  \"Statistics\",\n",
      "  \"Mathematics\",\n",
      "  \"Computer Science\",\n",
      "  \"IT\",\n",
      "  \"Machine Learning\",\n",
      "  \"Deep Learning\"\n",
      "]\n",
      "```\n",
      "2025-04-17 15:05:56,415 - ERROR - Failed to parse Gemini response as JSON\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "skills_text = \"Strong foundation in Statistics, Mathematics, Computer Science, and IT. Proficient in machine learning and deep learning techniques.\"\n",
    "skills = extract_skills_with_gemini(skills_text)\n",
    "print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ac64e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 15:06:15,995 - INFO - Connected to MongoDB Atlas\n",
      "2025-04-17 15:06:16,259 - INFO - Extracted text from page 1 using pdfplumber\n",
      "2025-04-17 15:06:16,260 - INFO - Extracted text from CV: SHASHIPRABHA\n",
      "SENANAYAKE\n",
      "Data Science Research Intern working on AI modelling with\n",
      "a strong passion f...\n",
      "2025-04-17 15:06:16,262 - INFO - Extracted skills section: Customer churn prediction for landline telephone services - Python Machine learning model to detect fraud in online payments – Python (scikit-learn) engineering capstone project] – Python (TensorFlow, OpenCV) E D U C A T I O N manufacturing companies– Python(scikit-learn) Twitter sentiment analysis - Python (scikit-learn, NLTK(natural language toolkit) University of Colombo market - Python, Excel, SPSS, R and Minitab Interactive dashboard to visualize global YouTube statistics for 2023 - PowerBI BSc(Hons) Applied Statistics Strong foundation in Statistics, Mathematics, Computer Science, and IT. Proficient in machine learning and deep learning techniques.\n",
      "2025-04-17 15:06:17,690 - INFO - Gemini raw response: ```json\n",
      "[\n",
      "  \"Machine Learning\",\n",
      "  \"Deep Learning\",\n",
      "  \"Python\",\n",
      "  \"TensorFlow\",\n",
      "  \"OpenCV\",\n",
      "  \"Scikit-learn\",\n",
      "  \"NLTK\",\n",
      "  \"Power BI\",\n",
      "  \"Excel\",\n",
      "  \"SPSS\",\n",
      "  \"R\",\n",
      "  \"Minitab\",\n",
      "  \"Statistics\",\n",
      "  \"Mathematics\",\n",
      "  \"Computer Science\",\n",
      "  \"IT\"\n",
      "]\n",
      "```\n",
      "2025-04-17 15:06:17,691 - ERROR - Failed to parse Gemini response as JSON\n",
      "2025-04-17 15:06:17,692 - ERROR - Failed to extract skills from CV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Failed to extract skills from CV. Check CV formatting, skills section content, or Gemini API response.'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run the Analysis\n",
    "cv_path = r\"C:\\Users\\shash\\Downloads\\Shashiprabha_Senanayake_Resume (3).pdf\"  # Replace with your CV path (e.g., \"path/to/your_cv.pdf\")\n",
    "dream_job_role = \"AI Governance Expert\"\n",
    "result = analyze_cv_skill_gap(cv_path, dream_job_role)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa1df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae851570",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------------------------(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e1e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Libraries and Setup\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Setup logging to debug issues\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Hardcode credentials\n",
    "GOOGLE_API_KEY = \"AIzaSyBvRnSojVCuojgtGI7RisnW6-S4VpBYJWo\"  # Replace with your Gemini API key\n",
    "MONGODB_URI = \"mongodb+srv://shashi:VSXV9WDNmRvYnA7p@clusterskillgapanalysis.vnbcnju.mongodb.net/skillgapanalysis?retryWrites=true&w=majority\"\n",
    "\n",
    "# Import dependencies and check if installed\n",
    "try:\n",
    "    import pdfplumber\n",
    "except ImportError:\n",
    "    raise ImportError(\"pdfplumber is not installed. Run: %pip install pdfplumber\")\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except ImportError:\n",
    "    raise ImportError(\"google-generativeai is not installed. Run: %pip install google-generativeai\")\n",
    "\n",
    "try:\n",
    "    import pytesseract\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    raise ImportError(\"pytesseract or PIL is not installed. Run: %pip install pytesseract Pillow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce692cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: MongoDB Connection\n",
    "def connect_to_mongodb():\n",
    "    try:\n",
    "        client = MongoClient(MONGODB_URI)\n",
    "        db = client[\"skillgapanalysis\"]\n",
    "        collection = db[\"jobrole_skill\"]\n",
    "        collection.create_index(\"Job_Role\")\n",
    "        logging.info(\"Connected to MongoDB Atlas\")\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to connect to MongoDB: {str(e)}\")\n",
    "        raise ValueError(f\"Failed to connect to MongoDB: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961199f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: CV Text Extraction\n",
    "def extract_cv_text(cv_path):\n",
    "    try:\n",
    "        with pdfplumber.open(cv_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "                    logging.info(f\"Extracted text from page {page.page_number} using pdfplumber\")\n",
    "                else:\n",
    "                    logging.warning(f\"No text extracted from page {page.page_number}. Using OCR.\")\n",
    "                    try:\n",
    "                        img = page.to_image().original\n",
    "                        ocr_text = pytesseract.image_to_string(img)\n",
    "                        text += ocr_text + \"\\n\"\n",
    "                        logging.info(f\"Extracted OCR text from page {page.page_number}\")\n",
    "                    except Exception as ocr_e:\n",
    "                        logging.error(f\"OCR failed for page {page.page_number}: {str(ocr_e)}\")\n",
    "                        text += \"\\n\"\n",
    "            if not text.strip():\n",
    "                raise ValueError(\"No text extracted from CV. Check PDF format or Tesseract installation.\")\n",
    "            logging.info(f\"Extracted text from CV: {text[:100]}...\")\n",
    "            return text\n",
    "    except pdfplumber.pdfminer.pdfdocument.PDFPasswordIncorrect:\n",
    "        logging.error(\"PDF is password-protected. Provide the password or use an unprotected PDF.\")\n",
    "        raise ValueError(\"PDF is password-protected\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading CV: {str(e)}\")\n",
    "        raise ValueError(f\"Error reading CV: {str(e)}\")\n",
    "\n",
    "# Cell 5: Skills Section Extraction\n",
    "def extract_skills_section(cv_text):\n",
    "    try:\n",
    "        match = re.search(\n",
    "            r\"(skills|technical skills|key skills):?\\s*(.*?)(?:\\n\\s*(experience|education|projects|contact|certifications|$))\",\n",
    "            cv_text, re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "        if match:\n",
    "            skills_text = match.group(2).strip()\n",
    "            skills_lines = [line for line in skills_text.split('\\n') if any(\n",
    "                keyword in line.lower() for keyword in [\n",
    "                    'proficient', 'strong', 'skills', 'machine learning', 'python', 'statistics',\n",
    "                    'tensorflow', 'scikit-learn', 'deep learning'\n",
    "                ]\n",
    "            ) or re.match(r'^\\s*[-•*]\\s', line)]\n",
    "            cleaned_skills = ' '.join(skills_lines).strip()\n",
    "            logging.info(f\"Extracted skills section: {cleaned_skills}\")\n",
    "            return cleaned_skills if cleaned_skills else None\n",
    "        logging.warning(\"No skills section found in CV text\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting skills section: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b3030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Gemini Skill Extraction\n",
    "def extract_skills_with_gemini(skills_text):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = (\n",
    "            \"Extract skills from this CV Skills section: \" + skills_text +\n",
    "            \". Return only a plain JSON array of clean, distinct skills (e.g., capitalize 'PyTorch', 'AWS SageMaker'). \" +\n",
    "            \"Combine similar skills (e.g., 'ML' and 'Machine Learning' as 'Machine Learning'). \" +\n",
    "            \"Return [] if no skills or input is empty. Output must be a valid JSON array without ```json, backticks, or any other formatting. \" +\n",
    "            \"Example: Input: 'Machine Learning, ML, PyTorch' Output: [\\\"Machine Learning\\\", \\\"PyTorch\\\"]\"\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        raw_response = response.text.strip()\n",
    "        logging.info(f\"Gemini raw response: {raw_response}\")\n",
    "        cleaned_response = raw_response\n",
    "        if cleaned_response.startswith(\"```json\\n\"):\n",
    "            cleaned_response = cleaned_response[8:].strip()\n",
    "        elif cleaned_response.startswith(\"```json\"):\n",
    "            cleaned_response = cleaned_response[7:].strip()\n",
    "        if cleaned_response.endswith(\"\\n```\"):\n",
    "            cleaned_response = cleaned_response[:-4].strip()\n",
    "        elif cleaned_response.endswith(\"```\"):\n",
    "            cleaned_response = cleaned_response[:-3].strip()\n",
    "        logging.info(f\"Cleaned Gemini response: {cleaned_response}\")\n",
    "        try:\n",
    "            skills = json.loads(cleaned_response)\n",
    "            if not isinstance(skills, list):\n",
    "                logging.error(\"Gemini response is not a JSON array\")\n",
    "                return []\n",
    "            logging.info(f\"Extracted skills: {skills}\")\n",
    "            return skills\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to parse cleaned Gemini response as JSON: {cleaned_response}, Error: {str(e)}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in Gemini skill extraction: {str(e)}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64e99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: MongoDB Query\n",
    "def get_required_skills(job_collection, job_role):\n",
    "    try:\n",
    "        job_doc = job_collection.find_one({\"Job_Role\": job_role})\n",
    "        if not job_doc:\n",
    "            raise ValueError(f\"Job role '{job_role}' not found in database\")\n",
    "        required_skills = [skill.strip() for skill in job_doc[\"Required_Skills\"].split(\",\")]\n",
    "        logging.info(f\"Required skills for {job_role}: {required_skills}\")\n",
    "        return required_skills\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving required skills: {str(e)}\")\n",
    "        raise ValueError(f\"Error retrieving required skills: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15f1145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Skill Gap Analysis\n",
    "def skill_gap_analysis(cv_skills, required_skills):\n",
    "    try:\n",
    "        cv_skills_set = set(skill.lower() for skill in cv_skills)\n",
    "        required_skills_set = set(skill.lower() for skill in required_skills)\n",
    "        missing_skills = required_skills_set - cv_skills_set\n",
    "        result = [skill for skill in required_skills if skill.lower() in missing_skills]\n",
    "        logging.info(f\"Missing skills: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in skill gap analysis: {str(e)}\")\n",
    "        raise ValueError(f\"Error in skill gap analysis: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea647d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Main Analysis Function\n",
    "def analyze_cv_skill_gap(cv_path, dream_job_role):\n",
    "    try:\n",
    "        job_collection = connect_to_mongodb()\n",
    "        cv_text = extract_cv_text(cv_path)\n",
    "        skills_text = extract_skills_section(cv_text)\n",
    "        if not skills_text:\n",
    "            logging.error(\"No skills section found in CV\")\n",
    "            return {\"error\": \"No skills section found in CV. Ensure the CV has a 'Skills' section.\"}\n",
    "        cv_skills = extract_skills_with_gemini(skills_text)\n",
    "        if not cv_skills:\n",
    "            logging.error(\"Failed to extract skills from CV\")\n",
    "            return {\"error\": \"Failed to extract skills from CV. Check CV formatting, skills section content, or Gemini API response.\"}\n",
    "        required_skills = get_required_skills(job_collection, dream_job_role)\n",
    "        missing_skills = skill_gap_analysis(cv_skills, required_skills)\n",
    "        result = {\n",
    "            \"job_role\": dream_job_role,\n",
    "            \"cv_skills\": cv_skills,\n",
    "            \"required_skills\": required_skills,\n",
    "            \"missing_skills\": missing_skills\n",
    "        }\n",
    "        logging.info(f\"Skill gap analysis result: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Skill gap analysis error: {str(e)}\")\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee99b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 15:23:09,156 - INFO - Connected to MongoDB Atlas\n",
      "2025-04-17 15:23:09,421 - INFO - Extracted text from page 1 using pdfplumber\n",
      "2025-04-17 15:23:09,422 - INFO - Extracted text from CV: SHASHIPRABHA\n",
      "SENANAYAKE\n",
      "Data Science Research Intern working on AI modelling with\n",
      "a strong passion f...\n",
      "2025-04-17 15:23:09,423 - INFO - Extracted skills section: Customer churn prediction for landline telephone services - Python Machine learning model to detect fraud in online payments – Python (scikit-learn) engineering capstone project] – Python (TensorFlow, OpenCV) E D U C A T I O N manufacturing companies– Python(scikit-learn) Twitter sentiment analysis - Python (scikit-learn, NLTK(natural language toolkit) University of Colombo market - Python, Excel, SPSS, R and Minitab Interactive dashboard to visualize global YouTube statistics for 2023 - PowerBI BSc(Hons) Applied Statistics Strong foundation in Statistics, Mathematics, Computer Science, and IT. Proficient in machine learning and deep learning techniques.\n",
      "2025-04-17 15:23:10,637 - INFO - Gemini raw response: [\"Python\", \"Machine Learning\", \"TensorFlow\", \"OpenCV\", \"Scikit-learn\", \"NLTK\", \"Excel\", \"SPSS\", \"R\", \"Minitab\", \"Power BI\", \"Statistics\", \"Mathematics\", \"Computer Science\", \"IT\", \"Deep Learning\"]\n",
      "2025-04-17 15:23:10,638 - INFO - Cleaned Gemini response: [\"Python\", \"Machine Learning\", \"TensorFlow\", \"OpenCV\", \"Scikit-learn\", \"NLTK\", \"Excel\", \"SPSS\", \"R\", \"Minitab\", \"Power BI\", \"Statistics\", \"Mathematics\", \"Computer Science\", \"IT\", \"Deep Learning\"]\n",
      "2025-04-17 15:23:10,639 - INFO - Extracted skills: ['Python', 'Machine Learning', 'TensorFlow', 'OpenCV', 'Scikit-learn', 'NLTK', 'Excel', 'SPSS', 'R', 'Minitab', 'Power BI', 'Statistics', 'Mathematics', 'Computer Science', 'IT', 'Deep Learning']\n",
      "2025-04-17 15:23:10,915 - INFO - Required skills for AI Governance Expert: ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision', 'TensorFlow']\n",
      "2025-04-17 15:23:10,916 - INFO - Missing skills: ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision']\n",
      "2025-04-17 15:23:10,917 - INFO - Skill gap analysis result: {'job_role': 'AI Governance Expert', 'cv_skills': ['Python', 'Machine Learning', 'TensorFlow', 'OpenCV', 'Scikit-learn', 'NLTK', 'Excel', 'SPSS', 'R', 'Minitab', 'Power BI', 'Statistics', 'Mathematics', 'Computer Science', 'IT', 'Deep Learning'], 'required_skills': ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision', 'TensorFlow'], 'missing_skills': ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job_role': 'AI Governance Expert', 'cv_skills': ['Python', 'Machine Learning', 'TensorFlow', 'OpenCV', 'Scikit-learn', 'NLTK', 'Excel', 'SPSS', 'R', 'Minitab', 'Power BI', 'Statistics', 'Mathematics', 'Computer Science', 'IT', 'Deep Learning'], 'required_skills': ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision', 'TensorFlow'], 'missing_skills': ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision']}\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run the Analysis\n",
    "cv_path = r\"C:\\Users\\shash\\Downloads\\Shashiprabha_Senanayake_Resume (3).pdf\"  # Replace with your CV path (e.g., \"path/to/your_cv.pdf\")\n",
    "dream_job_role = \"AI Governance Expert\"\n",
    "result = analyze_cv_skill_gap(cv_path, dream_job_role)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7829fd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 15:24:39,715 - INFO - Connected to MongoDB Atlas\n",
      "2025-04-17 15:24:39,736 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 15:24:39,990 - INFO - Extracted text from page 1 using pdfplumber\n",
      "2025-04-17 15:24:39,991 - INFO - Extracted text from CV: K A N DA C E L O U D O R\n",
      "DATA SCIENTIST\n",
      "CONTACT WORK EXPERIENCE\n",
      "kloudor@email.com Data Scientist\n",
      "(12...\n",
      "2025-04-17 15:24:39,992 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 15:24:39,993 - INFO - Extracted skills section: Python (NumPy, Pandas, Scikit-learn, Keras, Flask) Customer Segmentation recommendation engine in Python that improved the length on-\n",
      "2025-04-17 15:24:40,995 - INFO - Gemini raw response: [\"Python\", \"NumPy\", \"Pandas\", \"Scikit-learn\", \"Keras\", \"Flask\", \"Customer Segmentation\", \"Recommendation Engine\", \"Machine Learning\"]\n",
      "2025-04-17 15:24:40,998 - INFO - Cleaned Gemini response: [\"Python\", \"NumPy\", \"Pandas\", \"Scikit-learn\", \"Keras\", \"Flask\", \"Customer Segmentation\", \"Recommendation Engine\", \"Machine Learning\"]\n",
      "2025-04-17 15:24:40,999 - INFO - Extracted skills: ['Python', 'NumPy', 'Pandas', 'Scikit-learn', 'Keras', 'Flask', 'Customer Segmentation', 'Recommendation Engine', 'Machine Learning']\n",
      "2025-04-17 15:24:41,236 - INFO - Required skills for AI Governance Expert: ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision', 'TensorFlow']\n",
      "2025-04-17 15:24:41,237 - INFO - Missing skills: ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision', 'TensorFlow']\n",
      "2025-04-17 15:24:41,238 - INFO - Skill gap analysis result: {'job_role': 'AI Governance Expert', 'cv_skills': ['Python', 'NumPy', 'Pandas', 'Scikit-learn', 'Keras', 'Flask', 'Customer Segmentation', 'Recommendation Engine', 'Machine Learning'], 'required_skills': ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision', 'TensorFlow'], 'missing_skills': ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision', 'TensorFlow']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job_role': 'AI Governance Expert', 'cv_skills': ['Python', 'NumPy', 'Pandas', 'Scikit-learn', 'Keras', 'Flask', 'Customer Segmentation', 'Recommendation Engine', 'Machine Learning'], 'required_skills': ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision', 'TensorFlow'], 'missing_skills': ['ML Algorithms', 'Data Pipelines', 'AWS SageMaker', 'PyTorch', 'Statistical Modeling', 'NLP', 'Computer Vision', 'TensorFlow']}\n"
     ]
    }
   ],
   "source": [
    "cv_path = r\"C:\\Users\\shash\\Downloads\\data-scientist-resume-example.pdf\"  # Replace with your CV path (e.g., \"path/to/your_cv.pdf\")\n",
    "dream_job_role = \"AI Governance Expert\"\n",
    "result = analyze_cv_skill_gap(cv_path, dream_job_role)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdfd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------------------------------(4)Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "#%pip install pdfplumber pymongo google-generativeai dnspython pytesseract Pillow\n",
    "\n",
    "# Cell 2: Import Libraries and Setup\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Hardcode credentials\n",
    "GOOGLE_API_KEY = \"AIzaSyBvRnSojVCuojgtGI7RisnW6-S4VpBYJWo\"  # Replace with your Gemini API key\n",
    "MONGODB_URI = \"mongodb+srv://shashi:VSXV9WDNmRvYnA7p@clusterskillgapanalysis.vnbcnju.mongodb.net/skillgapanalysis?retryWrites=true&w=majority\"\n",
    "\n",
    "# Import dependencies\n",
    "try:\n",
    "    import pdfplumber\n",
    "except ImportError:\n",
    "    raise ImportError(\"pdfplumber is not installed. Run: %pip install pdfplumber\")\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except ImportError:\n",
    "    raise ImportError(\"google-generativeai is not installed. Run: %pip install google-generativeai\")\n",
    "\n",
    "try:\n",
    "    import pytesseract\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    raise ImportError(\"pytesseract or PIL is not installed. Run: %pip install pytesseract Pillow\")\n",
    "\n",
    "# Cell 3: MongoDB Connection\n",
    "def connect_to_mongodb():\n",
    "    try:\n",
    "        client = MongoClient(MONGODB_URI)\n",
    "        db = client[\"skillgapanalysis\"]\n",
    "        collection = db[\"jobrole_skill\"]\n",
    "        collection.create_index(\"Job_Role\")\n",
    "        logging.info(\"Connected to MongoDB Atlas\")\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to connect to MongoDB: {str(e)}\")\n",
    "        raise ValueError(f\"Failed to connect to MongoDB: {str(e)}\")\n",
    "\n",
    "# Cell 4: Enhanced CV Text Extraction\n",
    "def extract_cv_text(cv_path):\n",
    "    try:\n",
    "        with pdfplumber.open(cv_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\\n\"  # Double newline to separate pages\n",
    "                    logging.info(f\"Extracted text from page {page.page_number} using pdfplumber\")\n",
    "                else:\n",
    "                    logging.warning(f\"No text extracted from page {page.page_number}. Using OCR.\")#OCR=Optical Character Recognition\n",
    "                    try:\n",
    "                        img = page.to_image().original\n",
    "                        ocr_text = pytesseract.image_to_string(img)\n",
    "                        text += ocr_text + \"\\n\\n\"\n",
    "                        logging.info(f\"Extracted OCR text from page {page.page_number}\")\n",
    "                    except Exception as ocr_e:\n",
    "                        logging.error(f\"OCR failed for page {page.page_number}: {str(ocr_e)}\")\n",
    "                        text += \"\\n\\n\"\n",
    "            if not text.strip():\n",
    "                raise ValueError(\"No text extracted from CV. Check PDF format or Tesseract installation.\")\n",
    "            logging.info(f\"Extracted text from CV: {text[:100]}...\")\n",
    "            return text\n",
    "    except pdfplumber.pdfminer.pdfdocument.PDFPasswordIncorrect:\n",
    "        logging.error(\"PDF is password-protected. Provide the password or use an unprotected PDF.\")\n",
    "        raise ValueError(\"PDF is password-protected\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading CV: {str(e)}\")\n",
    "        raise ValueError(f\"Error reading CV: {str(e)}\")\n",
    "\n",
    "# Cell 5: Skills Section Extraction\n",
    "def extract_skills_section(cv_text):\n",
    "    try:\n",
    "        # Search for \"Skills\" section anywhere in the CV\n",
    "        match = re.search(\n",
    "            r\"(skills|technical skills|key skills|core competencies):?\\s*(.*?)(?=\\n\\s*(experience|education|projects|contact|certifications|references|$|\\n\\n))\",\n",
    "            cv_text, re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "        if match:\n",
    "            skills_text = match.group(2).strip()\n",
    "            # Include all non-empty lines\n",
    "            skills_lines = [line.strip() for line in skills_text.split('\\n') if line.strip() and not re.match(r'^\\s*$', line)]\n",
    "            cleaned_skills = ' '.join(skills_lines).strip()\n",
    "            logging.info(f\"Extracted skills section: {cleaned_skills}\")\n",
    "            return cleaned_skills if cleaned_skills else cv_text\n",
    "        logging.warning(\"No explicit skills section found. Using full CV text for Gemini.\")\n",
    "        return cv_text  # Fall back to full CV text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting skills section: {str(e)}\")\n",
    "        return cv_text\n",
    "\n",
    "# Cell 6: Gemini Skill Extraction\n",
    "def extract_skills_with_gemini(cv_text):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = (\n",
    "            \"You are an expert in CV analysis. Extract all skills from the following CV text, including: \"\n",
    "            \"1. Explicit skills listed in a 'Skills', 'Technical Skills', or similar section (e.g., 'Python, TensorFlow'). \"\n",
    "            \"2. Implicit skills inferred from 'Projects', 'Experience', or similar sections (e.g., 'Built a fraud detection model using scikit-learn' implies 'scikit-learn'). \"\n",
    "            \"Return a plain JSON array of clean, distinct skills (e.g., capitalize 'PyTorch', 'AWS SageMaker'). \"\n",
    "            \"Combine similar skills (e.g., 'ML' and 'Machine Learning' as 'Machine Learning'). \"\n",
    "            \"Return [] if no skills are found or input is empty. \"\n",
    "            \"Output must be a valid JSON array without ```json, backticks, or any other formatting. \"\n",
    "            \"Example: Input: 'Skills: Python, ML\\nProjects: Built a model using TensorFlow' \"\n",
    "            \"Output: [\\\"Python\\\", \\\"Machine Learning\\\", \\\"TensorFlow\\\"]\"\n",
    "            \"\\n\\nCV Text:\\n\" + cv_text\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        raw_response = response.text.strip()\n",
    "        logging.info(f\"Gemini raw response: {raw_response}\")\n",
    "        cleaned_response = raw_response\n",
    "        if cleaned_response.startswith(\"```json\\n\"):\n",
    "            cleaned_response = cleaned_response[8:].strip()\n",
    "        elif cleaned_response.startswith(\"```json\"):\n",
    "            cleaned_response = cleaned_response[7:].strip()\n",
    "        if cleaned_response.endswith(\"\\n```\"):\n",
    "            cleaned_response = cleaned_response[:-4].strip()\n",
    "        elif cleaned_response.endswith(\"```\"):\n",
    "            cleaned_response = cleaned_response[:-3].strip()\n",
    "        logging.info(f\"Cleaned Gemini response: {cleaned_response}\")\n",
    "        try:\n",
    "            skills = json.loads(cleaned_response)\n",
    "            if not isinstance(skills, list):\n",
    "                logging.error(\"Gemini response is not a JSON array\")\n",
    "                return []\n",
    "            logging.info(f\"Extracted skills: {skills}\")\n",
    "            return skills\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to parse cleaned Gemini response as JSON: {cleaned_response}, Error: {str(e)}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in Gemini skill extraction: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Cell 7: MongoDB Query\n",
    "def get_required_skills(job_collection, job_role):\n",
    "    try:\n",
    "        job_doc = job_collection.find_one({\"Job_Role\": job_role})\n",
    "        if not job_doc:\n",
    "            raise ValueError(f\"Job role '{job_role}' not found in database\")\n",
    "        required_skills = [skill.strip() for skill in job_doc[\"Required_Skills\"].split(\",\")]\n",
    "        logging.info(f\"Required skills for {job_role}: {required_skills}\")\n",
    "        return required_skills\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving required skills: {str(e)}\")\n",
    "        raise ValueError(f\"Error retrieving required skills: {str(e)}\")\n",
    "\n",
    "# Cell 8: Skill Gap Analysis\n",
    "def skill_gap_analysis(cv_skills, required_skills):\n",
    "    try:\n",
    "        cv_skills_set = set(skill.lower() for skill in cv_skills)\n",
    "        required_skills_set = set(skill.lower() for skill in required_skills)\n",
    "        missing_skills = required_skills_set - cv_skills_set\n",
    "        result = [skill for skill in required_skills if skill.lower() in missing_skills]\n",
    "        logging.info(f\"Missing skills: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in skill gap analysis: {str(e)}\")\n",
    "        raise ValueError(f\"Error in skill gap analysis: {str(e)}\")\n",
    "\n",
    "# Cell 9: Main Analysis Function\n",
    "def analyze_cv_skill_gap(cv_path, dream_job_role):\n",
    "    try:\n",
    "        job_collection = connect_to_mongodb()\n",
    "        cv_text = extract_cv_text(cv_path)\n",
    "        skills_text = extract_skills_section(cv_text)\n",
    "        cv_skills = extract_skills_with_gemini(skills_text)\n",
    "        if not cv_skills:\n",
    "            logging.error(\"Failed to extract skills from CV\")\n",
    "            return {\"error\": \"Failed to extract skills from CV. Check CV formatting, content, or Gemini API response.\"}\n",
    "        required_skills = get_required_skills(job_collection, dream_job_role)\n",
    "        missing_skills = skill_gap_analysis(cv_skills, required_skills)\n",
    "        result = {\n",
    "            \"job_role\": dream_job_role,\n",
    "            \"cv_skills\": cv_skills,\n",
    "            \"required_skills\": required_skills,\n",
    "            \"missing_skills\": missing_skills\n",
    "        }\n",
    "        logging.info(f\"Skill gap analysis result: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Skill gap analysis error: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695731c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------(5)(try-any file format*)\\/\\/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be58eab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.11.6)\n",
      "Requirement already satisfied: pymongo in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.12.0)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: dnspython in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (11.0.0)\n",
      "Requirement already satisfied: python-docx in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (20250327)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (44.0.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.166.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (5.29.2)\n",
      "Requirement already satisfied: pydantic in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.10.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shash\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\shash\\appdata\\roaming\\python\\python310\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\shash\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "%pip install pdfplumber pymongo google-generativeai dnspython pytesseract Pillow python-docx\n",
    "\n",
    "# Cell 2: Import Libraries and Setup\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Hardcode credentials\n",
    "GOOGLE_API_KEY = \"AIzaSyBvRnSojVCuojgtGI7RisnW6-S4VpBYJWo\"  # Replace with your Gemini API key\n",
    "MONGODB_URI = \"mongodb+srv://shashi:VSXV9WDNmRvYnA7p@clusterskillgapanalysis.vnbcnju.mongodb.net/skillgapanalysis?retryWrites=true&w=majority\"\n",
    "\n",
    "# Import dependencies\n",
    "try:\n",
    "    import pdfplumber\n",
    "except ImportError:\n",
    "    raise ImportError(\"pdfplumber is not installed. Run: %pip install pdfplumber\")\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except ImportError:\n",
    "    raise ImportError(\"google-generativeai is not installed. Run: %pip install google-generativeai\")\n",
    "\n",
    "try:\n",
    "    import pytesseract\n",
    "    # Explicitly set Tesseract path (adjust if installed elsewhere)\n",
    "    pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "except ImportError:\n",
    "    raise ImportError(\"pytesseract is not installed. Run: %pip install pytesseract\")\n",
    "\n",
    "try:\n",
    "    import docx\n",
    "except ImportError:\n",
    "    raise ImportError(\"python-docx is not installed. Run: %pip install python-docx\")\n",
    "\n",
    "# Cell 3: MongoDB Connection\n",
    "def connect_to_mongodb():\n",
    "    try:\n",
    "        client = MongoClient(MONGODB_URI)\n",
    "        db = client[\"skillgapanalysis\"]\n",
    "        collection = db[\"jobrole_skill\"]\n",
    "        collection.create_index(\"Job_Role\")\n",
    "        logging.info(\"Connected to MongoDB Atlas\")\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to connect to MongoDB: {str(e)}\")\n",
    "        raise ValueError(f\"Failed to connect to MongoDB: {str(e)}\")\n",
    "\n",
    "# Cell 4: Enhanced CV Text Extraction with Multi-Format Support\n",
    "def extract_cv_text(cv_path):\n",
    "    try:\n",
    "        if not os.path.exists(cv_path):\n",
    "            raise ValueError(f\"File not found: {cv_path}\")\n",
    "        \n",
    "        file_ext = os.path.splitext(cv_path)[1].lower()\n",
    "        \n",
    "        if file_ext in ['.png', '.jpg', '.jpeg']:\n",
    "            # Handle image files\n",
    "            try:\n",
    "                img = Image.open(cv_path)\n",
    "                text = pytesseract.image_to_string(img)\n",
    "                if not text.strip():\n",
    "                    raise ValueError(\"No text extracted from image. Check image quality or Tesseract installation. Ensure Tesseract is installed at 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe' or update the path in Cell 2.\")\n",
    "                logging.info(f\"Extracted text from image {cv_path}: {text[:100]}...\")\n",
    "                return text\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing image {cv_path}: {str(e)}\")\n",
    "                raise ValueError(f\"Error processing image: {str(e)}. Ensure Tesseract is installed and accessible.\")\n",
    "        \n",
    "        elif file_ext == '.pdf':\n",
    "            # Handle PDF files\n",
    "            with pdfplumber.open(cv_path) as pdf:\n",
    "                text = \"\"\n",
    "                table_text = \"\"\n",
    "                for page in pdf.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\\n\"\n",
    "                        logging.info(f\"Extracted text from page {page.page_number} using pdfplumber\")\n",
    "                    else:\n",
    "                        logging.warning(f\"No text extracted from page {page.page_number}. Using OCR.\")\n",
    "                        try:\n",
    "                            img = page.to_image().original\n",
    "                            ocr_text = pytesseract.image_to_string(img)\n",
    "                            text += ocr_text + \"\\n\\n\"\n",
    "                            logging.info(f\"Extracted OCR text from page {page.page_number}\")\n",
    "                        except Exception as ocr_e:\n",
    "                            logging.error(f\"OCR failed for page {page.page_number}: {str(ocr_e)}\")\n",
    "                            text += \"\\n\\n\"\n",
    "                    # Extract tables\n",
    "                    tables = page.extract_tables()\n",
    "                    for table in tables:\n",
    "                        for row in table:\n",
    "                            row_text = \" \".join([str(cell) for cell in row if cell]).strip()\n",
    "                            if row_text:\n",
    "                                table_text += row_text + \"\\n\"\n",
    "                        table_text += \"\\n\"\n",
    "                if table_text:\n",
    "                    text += \"\\nTable Content:\\n\" + table_text\n",
    "                    logging.info(f\"Extracted table content: {table_text[:100]}...\")\n",
    "                if not text.strip():\n",
    "                    raise ValueError(\"No text extracted from PDF. Check PDF format or Tesseract installation.\")\n",
    "                logging.info(f\"Extracted text from PDF {cv_path}: {text[:100]}...\")\n",
    "                return text\n",
    "        \n",
    "        elif file_ext == '.docx':\n",
    "            # Handle DOCX files\n",
    "            try:\n",
    "                doc = docx.Document(cv_path)\n",
    "                text = \"\"\n",
    "                for para in doc.paragraphs:\n",
    "                    text += para.text + \"\\n\"\n",
    "                # Extract tables\n",
    "                table_text = \"\"\n",
    "                for table in doc.tables:\n",
    "                    for row in table.rows:\n",
    "                        row_text = \" \".join([cell.text.strip() for cell in row.cells if cell.text.strip()])\n",
    "                        if row_text:\n",
    "                            table_text += row_text + \"\\n\"\n",
    "                    table_text += \"\\n\"\n",
    "                if table_text:\n",
    "                    text += \"\\nTable Content:\\n\" + table_text\n",
    "                    logging.info(f\"Extracted table content from DOCX: {table_text[:100]}...\")\n",
    "                if not text.strip():\n",
    "                    raise ValueError(\"No text extracted from DOCX. Check document content.\")\n",
    "                logging.info(f\"Extracted text from DOCX {cv_path}: {text[:100]}...\")\n",
    "                return text\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing DOCX {cv_path}: {str(e)}\")\n",
    "                raise ValueError(f\"Error processing DOCX: {str(e)}\")\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {file_ext}. Supported formats: .pdf, .png, .jpg, .jpeg, .docx\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading CV {cv_path}: {str(e)}\")\n",
    "        raise ValueError(f\"Error reading CV: {str(e)}\")\n",
    "\n",
    "# Cell 5: Skills Section Extraction\n",
    "def extract_skills_section(cv_text):\n",
    "    try:\n",
    "        match = re.search(\n",
    "            r\"(skills|technical skills|key skills|core competencies|proficiencies|expertise):?\\s*(.*?)(?=\\n\\s*(experience|education|projects|contact|certifications|references|table content|$|\\n\\n))\",\n",
    "            cv_text, re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "        if match:\n",
    "            skills_text = match.group(2).strip()\n",
    "            skills_lines = [line.strip() for line in skills_text.split('\\n') if line.strip() and not re.match(r'^\\s*$', line)]\n",
    "            cleaned_skills = ' '.join(skills_lines).strip()\n",
    "            logging.info(f\"Extracted skills section: {cleaned_skills}\")\n",
    "            return cleaned_skills if cleaned_skills else cv_text\n",
    "        logging.warning(\"No explicit skills section found. Using full CV text for Gemini.\")\n",
    "        return cv_text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting skills section: {str(e)}\")\n",
    "        return cv_text\n",
    "\n",
    "# Cell 6: Gemini Skill Extraction\n",
    "def extract_skills_with_gemini(cv_text):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = (\n",
    "            \"You are an expert in CV analysis. Extract all skills from the following CV text, including: \"\n",
    "            \"1. Explicit skills listed in a 'Skills', 'Technical Skills', 'Proficiencies', or similar section (e.g., 'Python, TensorFlow'). \"\n",
    "            \"2. Implicit skills inferred from 'Projects', 'Experience', or similar sections (e.g., 'Built a fraud detection model using scikit-learn' implies 'scikit-learn'). \"\n",
    "            \"3. Skills from tables or graph labels (e.g., 'Python: 80%' or 'TensorFlow Advanced' implies 'Python', 'TensorFlow'). \"\n",
    "            \"Return a plain JSON array of clean, distinct skills (e.g., capitalize 'PyTorch', 'AWS SageMaker'). \"\n",
    "            \"Combine similar skills (e.g., 'ML' and 'Machine Learning' as 'Machine Learning'). \"\n",
    "            \"Ignore proficiency levels or percentages (e.g., 'Python: 80%' → 'Python'). \"\n",
    "            \"Return [] if no skills are found or input is empty. \"\n",
    "            \"Output must be a valid JSON array without ```json, backticks, or any other formatting. \"\n",
    "            \"Example: Input: 'Skills: Python, ML\\nProjects: Built a model using TensorFlow\\nTable: Python Advanced' \"\n",
    "            \"Output: [\\\"Python\\\", \\\"Machine Learning\\\", \\\"TensorFlow\\\"]\"\n",
    "            \"\\n\\nCV Text:\\n\" + cv_text\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        raw_response = response.text.strip()\n",
    "        logging.info(f\"Gemini raw response: {raw_response}\")\n",
    "        cleaned_response = raw_response\n",
    "        if cleaned_response.startswith(\"```json\\n\"):\n",
    "            cleaned_response = cleaned_response[8:].strip()\n",
    "        elif cleaned_response.startswith(\"```json\"):\n",
    "            cleaned_response = cleaned_response[7:].strip()\n",
    "        if cleaned_response.endswith(\"\\n```\"):\n",
    "            cleaned_response = cleaned_response[:-4].strip()\n",
    "        elif cleaned_response.endswith(\"```\"):\n",
    "            cleaned_response = cleaned_response[:-3].strip()\n",
    "        logging.info(f\"Cleaned Gemini response: {cleaned_response}\")\n",
    "        try:\n",
    "            skills = json.loads(cleaned_response)\n",
    "            if not isinstance(skills, list):\n",
    "                logging.error(\"Gemini response is not a JSON array\")\n",
    "                return []\n",
    "            logging.info(f\"Extracted skills: {skills}\")\n",
    "            return skills\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to parse cleaned Gemini response as JSON: {cleaned_response}, Error: {str(e)}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in Gemini skill extraction: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Cell 7: MongoDB Query\n",
    "def get_required_skills(job_collection, job_role):\n",
    "    try:\n",
    "        job_doc = job_collection.find_one({\"Job_Role\": job_role})\n",
    "        if not job_doc:\n",
    "            raise ValueError(f\"Job role '{job_role}' not found in database\")\n",
    "        required_skills = [skill.strip() for skill in job_doc[\"Required_Skills\"].split(\",\")]\n",
    "        logging.info(f\"Required skills for {job_role}: {required_skills}\")\n",
    "        return required_skills\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving required skills: {str(e)}\")\n",
    "        raise ValueError(f\"Error retrieving required skills: {str(e)}\")\n",
    "\n",
    "# Cell 8: Skill Gap Analysis\n",
    "def skill_gap_analysis(cv_skills, required_skills):\n",
    "    try:\n",
    "        cv_skills_set = set(skill.lower() for skill in cv_skills)\n",
    "        required_skills_set = set(skill.lower() for skill in required_skills)\n",
    "        missing_skills = required_skills_set - cv_skills_set\n",
    "        result = [skill for skill in required_skills if skill.lower() in missing_skills]\n",
    "        logging.info(f\"Missing skills: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in skill gap analysis: {str(e)}\")\n",
    "        raise ValueError(f\"Error in skill gap analysis: {str(e)}\")\n",
    "\n",
    "# Cell 9: Main Analysis Function\n",
    "def analyze_cv_skill_gap(cv_path, dream_job_role):\n",
    "    try:\n",
    "        job_collection = connect_to_mongodb()\n",
    "        cv_text = extract_cv_text(cv_path)\n",
    "        skills_text = extract_skills_section(cv_text)\n",
    "        cv_skills = extract_skills_with_gemini(skills_text)\n",
    "        if not cv_skills:\n",
    "            logging.error(\"Failed to extract skills from CV\")\n",
    "            return {\"error\": \"Failed to extract skills from CV. Check CV formatting, content, or Gemini API response.\"}\n",
    "        required_skills = get_required_skills(job_collection, dream_job_role)\n",
    "        missing_skills = skill_gap_analysis(cv_skills, required_skills)\n",
    "        result = {\n",
    "            \"job_role\": dream_job_role,\n",
    "            \"cv_skills\": cv_skills,\n",
    "            \"required_skills\": required_skills,\n",
    "            \"missing_skills\": missing_skills\n",
    "        }\n",
    "        logging.info(f\"Skill gap analysis result: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Skill gap analysis error: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a8040f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 16:39:01,907 - INFO - Connected to MongoDB Atlas\n",
      "2025-04-17 16:39:04,113 - INFO - Extracted text from image C:\\Users\\shash\\Downloads\\cvsample1.png: JACOB ROBERTS\n",
      "\n",
      "Product Manager | PaaS Expertise | Strategic Vision\n",
      "\\ +44 207123 4567 @ help@enhancv....\n",
      "2025-04-17 16:39:04,115 - INFO - Extracted skills section: | Strategic Vision \\ +44 207123 4567 @ help@enhancv.com @ linkedin.com 9 Edinburgh, UK SUMMARY\n",
      "2025-04-17 16:39:05,080 - INFO - Gemini raw response: []\n",
      "2025-04-17 16:39:05,082 - INFO - Cleaned Gemini response: []\n",
      "2025-04-17 16:39:05,082 - INFO - Extracted skills: []\n",
      "2025-04-17 16:39:05,083 - ERROR - Failed to extract skills from CV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Failed to extract skills from CV. Check CV formatting, content, or Gemini API response.'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run the Analysis\n",
    "cv_path = r\"C:\\Users\\shash\\Downloads\\cvsample1.png\"\n",
    "dream_job_role = \"AI Governance Expert\"\n",
    "result = analyze_cv_skill_gap(cv_path, dream_job_role)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
