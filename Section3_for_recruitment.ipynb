{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712f5a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.11.6)\n",
      "Requirement already satisfied: pymongo in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.12.0)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: dnspython in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (11.0.0)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (20250327)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (44.0.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.166.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (5.29.2)\n",
      "Requirement already satisfied: pydantic in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.10.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shash\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\shash\\appdata\\roaming\\python\\python310\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\shash\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "%pip install pdfplumber pymongo google-generativeai dnspython pytesseract Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2069da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Libraries and Setup\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Hardcode credentials\n",
    "GOOGLE_API_KEY = \"AIzaSyBvRnSojVCuojgtGI7RisnW6-S4VpBYJWo\"  # Your provided Gemini API key\n",
    "MONGODB_URI = \"mongodb+srv://shashi:VSXV9WDNmRvYnA7p@clusterskillgapanalysis.vnbcnju.mongodb.net/skillgapanalysis?retryWrites=true&w=majority\"\n",
    "\n",
    "# Import dependencies\n",
    "try:\n",
    "    import pdfplumber\n",
    "except ImportError:\n",
    "    raise ImportError(\"pdfplumber is not installed. Run: %pip install pdfplumber\")\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except ImportError:\n",
    "    raise ImportError(\"google-generativeai is not installed. Run: %pip install google-generativeai\")\n",
    "\n",
    "try:\n",
    "    import pytesseract\n",
    "    # Explicitly set Tesseract path (adjust if installed elsewhere)\n",
    "    pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "except ImportError:\n",
    "    raise ImportError(\"pytesseract or PIL is not installed. Run: %pip install pytesseract Pillow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "252e8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: MongoDB Connection\n",
    "def connect_to_mongodb():\n",
    "    try:\n",
    "        client = MongoClient(MONGODB_URI)\n",
    "        db = client[\"skillgapanalysis\"]\n",
    "        collection = db[\"jobrole_skill\"]\n",
    "        collection.create_index(\"Job_Role\")\n",
    "        logging.info(\"Connected to MongoDB Atlas\")\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to connect to MongoDB: {str(e)}\")\n",
    "        raise ValueError(f\"Failed to connect to MongoDB: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "851787de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 4: Enhanced CV Text Extraction\n",
    "def extract_cv_text(cv_path):\n",
    "    try:\n",
    "        with pdfplumber.open(cv_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\\n\"\n",
    "                    logging.info(f\"Extracted text from page {page.page_number} using pdfplumber\")\n",
    "                else:\n",
    "                    logging.warning(f\"No text extracted from page {page.page_number}. Using OCR.\")\n",
    "                    try:\n",
    "                        img = page.to_image().original\n",
    "                        ocr_text = pytesseract.image_to_string(img)\n",
    "                        text += ocr_text + \"\\n\\n\"\n",
    "                        logging.info(f\"Extracted OCR text from page {page.page_number}\")\n",
    "                    except Exception as ocr_e:\n",
    "                        logging.error(f\"OCR failed for page {page.page_number}: {str(ocr_e)}\")\n",
    "                        text += \"\\n\\n\"\n",
    "            if not text.strip():\n",
    "                raise ValueError(\"No text extracted from CV. Check PDF format or Tesseract installation.\")\n",
    "            logging.info(f\"Extracted text from CV: {text[:100]}...\")\n",
    "            return text\n",
    "    except pdfplumber.pdfminer.pdfdocument.PDFPasswordIncorrect:\n",
    "        logging.error(\"PDF is password-protected. Provide the password or use an unprotected PDF.\")\n",
    "        raise ValueError(\"PDF is password-protected\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading CV: {str(e)}\")\n",
    "        raise ValueError(f\"Error reading CV: {str(e)}\")\n",
    "\n",
    "# Cell 5: Skills Section Extraction\n",
    "def extract_skills_section(cv_text):\n",
    "    try:\n",
    "        match = re.search(\n",
    "            r\"(skills|technical skills|key skills|core competencies):?\\s*(.*?)(?=\\n\\s*(experience|education|projects|contact|certifications|references|$|\\n\\n))\",\n",
    "            cv_text, re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "        if match:\n",
    "            skills_text = match.group(2).strip()\n",
    "            skills_lines = [line.strip() for line in skills_text.split('\\n') if line.strip() and not re.match(r'^\\s*$', line)]\n",
    "            cleaned_skills = ' '.join(skills_lines).strip()\n",
    "            logging.info(f\"Extracted skills section: {cleaned_skills}\")\n",
    "            return cleaned_skills if cleaned_skills else cv_text\n",
    "        logging.warning(\"No explicit skills section found. Using full CV text for Gemini.\")\n",
    "        return cv_text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting skills section: {str(e)}\")\n",
    "        return cv_text\n",
    "\n",
    "# Cell 6: Gemini Skill Extraction\n",
    "def extract_skills_with_gemini(cv_text):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = (\n",
    "            \"You are an expert in CV analysis. Extract all skills from the following CV text, including: \"\n",
    "            \"1. Explicit skills listed in a 'Skills', 'Technical Skills', or similar section (e.g., 'Python, TensorFlow'). \"\n",
    "            \"2. Implicit skills inferred from 'Projects', 'Experience', or similar sections (e.g., 'Built a fraud detection model using scikit-learn' implies 'scikit-learn'). \"\n",
    "            \"Return a plain JSON array of clean, distinct skills (e.g., capitalize 'PyTorch', 'AWS SageMaker'). \"\n",
    "            \"Combine similar skills (e.g., 'ML' and 'Machine Learning' as 'Machine Learning'). \"\n",
    "            \"Return [] if no skills are found or input is empty. \"\n",
    "            \"Output must be a valid JSON array without ```json, backticks, or any other formatting. \"\n",
    "            \"Example: Input: 'Skills: Python, ML\\nProjects: Built a model using TensorFlow' \"\n",
    "            \"Output: [\\\"Python\\\", \\\"Machine Learning\\\", \\\"TensorFlow\\\"]\"\n",
    "            \"\\n\\nCV Text:\\n\" + cv_text\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        raw_response = response.text.strip()\n",
    "        logging.info(f\"Gemini raw response: {raw_response}\")\n",
    "        cleaned_response = raw_response\n",
    "        if cleaned_response.startswith(\"```json\\n\"):\n",
    "            cleaned_response = cleaned_response[8:].strip()\n",
    "        elif cleaned_response.startswith(\"```json\"):\n",
    "            cleaned_response = cleaned_response[7:].strip()\n",
    "        if cleaned_response.endswith(\"\\n```\"):\n",
    "            cleaned_response = cleaned_response[:-4].strip()\n",
    "        elif cleaned_response.endswith(\"```\"):\n",
    "            cleaned_response = cleaned_response[:-3].strip()\n",
    "        logging.info(f\"Cleaned Gemini response: {cleaned_response}\")\n",
    "        try:\n",
    "            skills = json.loads(cleaned_response)\n",
    "            if not isinstance(skills, list):\n",
    "                logging.error(\"Gemini response is not a JSON array\")\n",
    "                return []\n",
    "            logging.info(f\"Extracted skills: {skills}\")\n",
    "            return skills\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to parse cleaned Gemini response as JSON: {cleaned_response}, Error: {str(e)}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in Gemini skill extraction: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Cell 7: MongoDB Query\n",
    "def get_required_skills(job_collection, job_role):\n",
    "    try:\n",
    "        job_doc = job_collection.find_one({\"Job_Role\": job_role})\n",
    "        if not job_doc:\n",
    "            raise ValueError(f\"Job role '{job_role}' not found in database\")\n",
    "        required_skills = [skill.strip() for skill in job_doc[\"Required_Skills\"].split(\",\")]\n",
    "        logging.info(f\"Required skills for {job_role}: {required_skills}\")\n",
    "        return required_skills\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving required skills: {str(e)}\")\n",
    "        raise ValueError(f\"Error retrieving required skills: {str(e)}\")\n",
    "\n",
    "# Cell 8: Skill Gap Analysis with Gemini Semantic Similarity\n",
    "def skill_gap_analysis(cv_skills, required_skills):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = (\n",
    "            \"You are an expert in skill gap analysis. Given two lists of skills: \"\n",
    "            \"1. CV skills (from a candidate's CV). \"\n",
    "            \"2. Required skills (for a job role). \"\n",
    "            \"Identify which required skills are missing from the CV skills, considering semantic similarity and synonyms. \"\n",
    "            \"Treat skills as equivalent if they have the same or similar meaning (e.g., 'ML' ≈ 'Machine Learning', \"\n",
    "            \"'SQL' ≈ 'Database Management', 'Statistical Analysis' ≈ 'Statistics', 'Deep Learning' ≈ 'Neural Networks'). \"\n",
    "            \"Return a plain JSON array of the missing required skills, preserving their original names from the required skills list. \"\n",
    "            \"Output must be a valid JSON array without ```json or backticks. \"\n",
    "            \"Example: \"\n",
    "            \"CV skills: ['Python', 'SQL', 'Deep Learning'] \"\n",
    "            \"Required skills: ['Database Management', 'Neural Networks', 'Data Pipelines'] \"\n",
    "            \"Output: ['Data Pipelines'] \"\n",
    "            \"\\n\\nCV Skills:\\n\" + json.dumps(cv_skills) +\n",
    "            \"\\nRequired Skills:\\n\" + json.dumps(required_skills)\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        raw_response = response.text.strip()\n",
    "        logging.info(f\"Gemini raw response for skill gap: {raw_response}\")\n",
    "        cleaned_response = raw_response\n",
    "        if cleaned_response.startswith(\"```json\\n\"):\n",
    "            cleaned_response = cleaned_response[8:].strip()\n",
    "        elif cleaned_response.startswith(\"```json\"):\n",
    "            cleaned_response = cleaned_response[7:].strip()\n",
    "        if cleaned_response.endswith(\"\\n```\"):\n",
    "            cleaned_response = cleaned_response[:-4].strip()\n",
    "        elif cleaned_response.endswith(\"```\"):\n",
    "            cleaned_response = cleaned_response[:-3].strip()\n",
    "        logging.info(f\"Cleaned Gemini response for skill gap: {cleaned_response}\")\n",
    "        try:\n",
    "            missing_skills = json.loads(cleaned_response)\n",
    "            if not isinstance(missing_skills, list):\n",
    "                logging.error(\"Gemini response is not a JSON array\")\n",
    "                return []\n",
    "            logging.info(f\"Missing skills: {missing_skills}\")\n",
    "            return missing_skills\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to parse Gemini response: {cleaned_response}, Error: {str(e)}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in skill gap analysis: {str(e)}\")\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a213b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Experience, Skill Weighting, and Ranking\n",
    "def extract_experience(cv_text):\n",
    "    try:\n",
    "        # Regex for explicit years of experience\n",
    "        year_patterns = [\n",
    "            r\"(\\d+)\\s*(?:years?|yrs?)\\s*(?:of\\s*)?(?:experience|professional experience)\",\n",
    "            r\"(\\d+)\\s*\\+?\\s*years?\\s*(?:of\\s*)?(?:experience|professional experience)\",\n",
    "            r\"experience\\s*:\\s*(\\d+)\\s*years?\"\n",
    "        ]\n",
    "        for pattern in year_patterns:\n",
    "            match = re.search(pattern, cv_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                years = int(match.group(1))\n",
    "                logging.info(f\"Extracted experience: {years} years\")\n",
    "                return years\n",
    "\n",
    "        # Fallback to Gemini for ambiguous cases (e.g., \"Senior Data Scientist since 2010\")\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = (\n",
    "            \"Extract the total years of professional experience from the following CV text. \"\n",
    "            \"Look for explicit mentions (e.g., '10 years of experience') or infer from job history (e.g., 'Senior Data Scientist since 2010'). \"\n",
    "            \"Return a single integer representing total years of experience. If no experience is found, return 0. \"\n",
    "            \"Output only the integer, nothing else. \"\n",
    "            \"Current year is 2025. \"\n",
    "            \"\\n\\nCV Text:\\n\" + cv_text[:2000]  # Limit to avoid token limits\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        years = int(response.text.strip())\n",
    "        logging.info(f\"Gemini extracted experience: {years} years\")\n",
    "        return years\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting experience: {str(e)}\")\n",
    "        return 0\n",
    "\n",
    "def assign_experience_weight(years):\n",
    "    if years > 15:\n",
    "        return 3  # High\n",
    "    elif 8 <= years <= 15:\n",
    "        return 2  # Medium\n",
    "    elif 1 <= years <= 7:\n",
    "        return 1  # Low\n",
    "    return 0  # None or <1 year\n",
    "\n",
    "def assign_skill_weights(job_role, required_skills):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        num_skills = len(required_skills)\n",
    "        # Dynamic weights: highest is num_skills, lowest is 1\n",
    "        prompt = (\n",
    "            f\"You are an expert in recruitment for the job role '{job_role}'. \"\n",
    "            f\"Given the following required skills: {json.dumps(required_skills)}, \"\n",
    "            f\"assign a weight to each skill based on its relevance to the job role. \"\n",
    "            f\"Use integers from 1 (least relevant) to {num_skills} (most relevant), ensuring each skill gets a unique weight. \"\n",
    "            \"Consider technical skills (e.g., 'Python' for Data Scientist) as more relevant than soft or unrelated skills (e.g., 'Hiking'). \"\n",
    "            \"Return a JSON object mapping each skill to its weight. \"\n",
    "            \"Output must be a valid JSON object without ```json or backticks. \"\n",
    "            \"Example: \"\n",
    "            \"Job role: Data Scientist \"\n",
    "            \"Required skills: ['Python', 'Report Writing', 'Hiking'] \"\n",
    "            \"Output: {\\\"Python\\\": 3, \\\"Report Writing\\\": 2, \\\"Hiking\\\": 1}\"\n",
    "            \"\\n\\nRequired Skills:\\n\" + json.dumps(required_skills)\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        raw_response = response.text.strip()\n",
    "        logging.info(f\"Gemini raw response for skill weights: {raw_response}\")\n",
    "        cleaned_response = raw_response\n",
    "        if cleaned_response.startswith(\"```json\\n\"):\n",
    "            cleaned_response = cleaned_response[8:].strip()\n",
    "        elif cleaned_response.startswith(\"```json\"):\n",
    "            cleaned_response = cleaned_response[7:].strip()\n",
    "        if cleaned_response.endswith(\"\\n```\"):\n",
    "            cleaned_response = cleaned_response[:-4].strip()\n",
    "        elif cleaned_response.endswith(\"```\"):\n",
    "            cleaned_response = cleaned_response[:-3].strip()\n",
    "        logging.info(f\"Cleaned Gemini response for skill weights: {cleaned_response}\")\n",
    "        try:\n",
    "            weights = json.loads(cleaned_response)\n",
    "            if not isinstance(weights, dict):\n",
    "                logging.error(\"Gemini response is not a JSON object\")\n",
    "                return {skill: 1 for skill in required_skills}  # Fallback: equal weights\n",
    "            logging.info(f\"Skill weights: {weights}\")\n",
    "            return weights\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to parse Gemini response: {cleaned_response}, Error: {str(e)}\")\n",
    "            return {skill: 1 for skill in required_skills}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error assigning skill weights: {str(e)}\")\n",
    "        return {skill: 1 for skill in required_skills}\n",
    "\n",
    "def rank_cvs(cv_folder, job_role):\n",
    "    try:\n",
    "        job_collection = connect_to_mongodb()\n",
    "        required_skills = get_required_skills(job_collection, job_role)\n",
    "        skill_weights = assign_skill_weights(job_role, required_skills)\n",
    "        cv_results = []\n",
    "\n",
    "        # Process each PDF CV in the folder\n",
    "        for cv_file in os.listdir(cv_folder):\n",
    "            if cv_file.lower().endswith('.pdf'):\n",
    "                cv_path = os.path.join(cv_folder, cv_file)\n",
    "                try:\n",
    "                    # Extract text and skills\n",
    "                    cv_text = extract_cv_text(cv_path)\n",
    "                    skills_text = extract_skills_section(cv_text)\n",
    "                    cv_skills = extract_skills_with_gemini(skills_text)\n",
    "                    if not cv_skills:\n",
    "                        logging.warning(f\"No skills extracted from {cv_file}\")\n",
    "                        continue\n",
    "\n",
    "                    # Extract experience\n",
    "                    years = extract_experience(cv_text)\n",
    "                    exp_weight = assign_experience_weight(years)\n",
    "\n",
    "                    # Skill gap analysis\n",
    "                    missing_skills = skill_gap_analysis(cv_skills, required_skills)\n",
    "\n",
    "                    # Calculate score\n",
    "                    skill_score = sum(skill_weights.get(skill, 0) for skill in cv_skills if skill in required_skills)\n",
    "                    total_score = exp_weight + skill_score\n",
    "\n",
    "                    cv_results.append({\n",
    "                        \"cv_file\": cv_file,\n",
    "                        \"years_experience\": years,\n",
    "                        \"experience_weight\": exp_weight,\n",
    "                        \"cv_skills\": cv_skills,\n",
    "                        \"required_skills\": required_skills,\n",
    "                        \"missing_skills\": missing_skills,\n",
    "                        \"skill_score\": skill_score,\n",
    "                        \"total_score\": total_score\n",
    "                    })\n",
    "                    logging.info(f\"Processed {cv_file}: Score = {total_score}\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing {cv_file}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "        # Rank CVs by total_score\n",
    "        ranked_cvs = sorted(cv_results, key=lambda x: x[\"total_score\"], reverse=True)\n",
    "        logging.info(f\"Ranked {len(ranked_cvs)} CVs\")\n",
    "        return ranked_cvs\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in CV ranking: {str(e)}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5972447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 21:25:42,380 - INFO - Connected to MongoDB Atlas\n",
      "2025-04-17 21:25:42,688 - INFO - Required skills for Data Scientist: ['ETL', 'Excel', 'A/B Testing', 'Data Visualization', 'Big Data']\n",
      "2025-04-17 21:25:43,814 - INFO - Gemini raw response for skill weights: {\n",
      "  \"Big Data\": 5,\n",
      "  \"ETL\": 4,\n",
      "  \"Data Visualization\": 3,\n",
      "  \"A/B Testing\": 2,\n",
      "  \"Excel\": 1\n",
      "}\n",
      "2025-04-17 21:25:43,815 - INFO - Cleaned Gemini response for skill weights: {\n",
      "  \"Big Data\": 5,\n",
      "  \"ETL\": 4,\n",
      "  \"Data Visualization\": 3,\n",
      "  \"A/B Testing\": 2,\n",
      "  \"Excel\": 1\n",
      "}\n",
      "2025-04-17 21:25:43,816 - INFO - Skill weights: {'Big Data': 5, 'ETL': 4, 'Data Visualization': 3, 'A/B Testing': 2, 'Excel': 1}\n",
      "2025-04-17 21:25:43,830 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:25:44,106 - INFO - Extracted text from page 1 using pdfplumber\n",
      "2025-04-17 21:25:44,108 - INFO - Extracted text from CV: K A N DA C E L O U D O R\n",
      "DATA SCIENTIST\n",
      "CONTACT WORK EXPERIENCE\n",
      "kloudor@email.com Data Scientist\n",
      "(12...\n",
      "2025-04-17 21:25:44,109 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:25:44,110 - INFO - Extracted skills section: Spectrix Analytical Services March 2016 - June 2018 / Princeton, NJ Python (NumPy, Pandas, Built a customer attrition random forest model that improved Scikit-learn, Keras, Flask) monthly retention by 12 basis points for clients likely to opt-out SQL (MySQL, Postgres) by providing relevant product features for them Git Coordinated with the product and marketing teams to determine Time Series Forecasting what kind of client interactions resulted in maximized service Productionizing Models opt-ins, increasing conversions by 18% Recommendation Engines Partnered with product team to create a production Customer Segmentation recommendation engine in Python that improved the length on- AWS page for users with $225K in incremental annual revenue Compiled and analyzed data surrounding the prototypes for a prosthesis, which saved over $1M in its creation Entry-Level Data Analyst Avenica April 2015 - March 2016 / Mount Laurel, NJ Collaborated with product managers to perform cohort analysis that identified an opportunity to reduce pricing by 21% for a segment of users to boost yearly revenue by $560,000 Constructed operational reporting in Tableau to improve scheduling contractors, saving $90,000 in the annual budget Implemented a long-term pricing experiment that improved customer lifetime value by 23% Ran, submitted, and reported on monthly client enrollments, services opted in for, and the employees assigned to clients\n",
      "2025-04-17 21:25:45,316 - INFO - Gemini raw response: [\"Python\", \"NumPy\", \"Pandas\", \"Scikit-learn\", \"Keras\", \"Flask\", \"SQL\", \"MySQL\", \"Postgres\", \"Git\", \"Time Series Forecasting\", \"Productionizing Models\", \"Recommendation Engines\", \"AWS\", \"Customer Segmentation\", \"Cohort Analysis\", \"Tableau\", \"A/B Testing\"]\n",
      "2025-04-17 21:25:45,318 - INFO - Cleaned Gemini response: [\"Python\", \"NumPy\", \"Pandas\", \"Scikit-learn\", \"Keras\", \"Flask\", \"SQL\", \"MySQL\", \"Postgres\", \"Git\", \"Time Series Forecasting\", \"Productionizing Models\", \"Recommendation Engines\", \"AWS\", \"Customer Segmentation\", \"Cohort Analysis\", \"Tableau\", \"A/B Testing\"]\n",
      "2025-04-17 21:25:45,319 - INFO - Extracted skills: ['Python', 'NumPy', 'Pandas', 'Scikit-learn', 'Keras', 'Flask', 'SQL', 'MySQL', 'Postgres', 'Git', 'Time Series Forecasting', 'Productionizing Models', 'Recommendation Engines', 'AWS', 'Customer Segmentation', 'Cohort Analysis', 'Tableau', 'A/B Testing']\n",
      "2025-04-17 21:25:46,271 - INFO - Gemini extracted experience: 7 years\n",
      "2025-04-17 21:25:47,185 - INFO - Gemini raw response for skill gap: [\"ETL\", \"Excel\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:25:47,185 - INFO - Cleaned Gemini response for skill gap: [\"ETL\", \"Excel\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:25:47,186 - INFO - Missing skills: ['ETL', 'Excel', 'Data Visualization', 'Big Data']\n",
      "2025-04-17 21:25:47,187 - INFO - Processed data-scientist-resume-example.pdf: Score = 3\n",
      "2025-04-17 21:25:47,215 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:25:47,220 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:25:47,428 - INFO - Extracted text from page 1 using pdfplumber\n",
      "2025-04-17 21:25:47,593 - INFO - Extracted text from page 2 using pdfplumber\n",
      "2025-04-17 21:25:47,593 - INFO - Extracted text from CV: Nimantha Kankanamge\n",
      "nimanthak0718@gmail.com 0767664176\n",
      "Kandy, Sri Lanka 18/07/1999 Male\n",
      "nimantha-kan...\n",
      "2025-04-17 21:25:47,594 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:25:47,595 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:25:47,596 - INFO - Extracted skills section: Water quality testing and chemical Statistical Analysis Using R Studio experiments Teamwork and Collaboration Data Analysis Photography and Editing Project Management Organizations Environmental Science Society- University of Peradeniya, 2023 – 2024 Committee Member perabeats Media Society-University of Peradeniya, Junior Treasurer 2023 – 2024 Managed the budget throughout the year while coordinating projects within the society. perabeats Media Society - University of Peradeniya, Senior Coordinator 2022 – 2023 Coordinate photographers, Editing and publishing photographs while managing the society’s page. Also worked as a photographer and editor.\n",
      "2025-04-17 21:25:48,934 - INFO - Gemini raw response: [\"Statistical Analysis\", \"R Studio\", \"Teamwork\", \"Collaboration\", \"Data Analysis\", \"Photography\", \"Editing\", \"Project Management\", \"Environmental Science\"]\n",
      "2025-04-17 21:25:48,936 - INFO - Cleaned Gemini response: [\"Statistical Analysis\", \"R Studio\", \"Teamwork\", \"Collaboration\", \"Data Analysis\", \"Photography\", \"Editing\", \"Project Management\", \"Environmental Science\"]\n",
      "2025-04-17 21:25:48,936 - INFO - Extracted skills: ['Statistical Analysis', 'R Studio', 'Teamwork', 'Collaboration', 'Data Analysis', 'Photography', 'Editing', 'Project Management', 'Environmental Science']\n",
      "2025-04-17 21:25:49,958 - INFO - Gemini extracted experience: 1 years\n",
      "2025-04-17 21:25:51,767 - INFO - Gemini raw response for skill gap: [\"ETL\", \"Excel\", \"A/B Testing\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:25:51,769 - INFO - Cleaned Gemini response for skill gap: [\"ETL\", \"Excel\", \"A/B Testing\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:25:51,769 - INFO - Missing skills: ['ETL', 'Excel', 'A/B Testing', 'Data Visualization', 'Big Data']\n",
      "2025-04-17 21:25:51,770 - INFO - Processed Nimantha_Kankanamge_Resume.pdf: Score = 1\n",
      "2025-04-17 21:25:52,086 - INFO - Extracted text from page 1 using pdfplumber\n",
      "2025-04-17 21:25:52,088 - INFO - Extracted text from CV: SHASHIPRABHA\n",
      "SENANAYAKE\n",
      "Data Science Research Intern working on AI modelling with\n",
      "a strong passion f...\n",
      "2025-04-17 21:25:52,088 - INFO - Extracted skills section: and grow in a dynamic environment. C O N T A C T P R O J E C T S AI powered skill gap analysis system (Ongoing) +94 70 5523737 LSTM model to predict dissolved oxygen levels in ponds in Myanmar, deployed shashiprabhasenanayake@gmail.com via Streamlit and integrated with Wix. - Final year research Customer churn prediction for landline telephone services - Python shashiprabha-senanayake Machine learning model to detect fraud in online payments – Python (scikit-learn) shashiprabha-senanayake Convolutional neural network to detect cracks on the concrete surface, [IBM AI engineering capstone project] – Python (TensorFlow, OpenCV) Regression model to predict the productivity of employees in garment E D U C A T I O N manufacturing companies– Python(scikit-learn) Twitter sentiment analysis - Python (scikit-learn, NLTK(natural language toolkit) Data analysis on the Impact of undergraduate preferences on Sri Lankan job University of Colombo market - Python, Excel, SPSS, R and Minitab Interactive dashboard to visualize global YouTube statistics for 2023 - PowerBI BSc(Hons) Applied Statistics Interactive dashboard to present electric vehicle population data - R shiny 2021 - 2025 Analyse the reasons for the customer complaints on their internet connection issues - SPSS, Excel Girls’ High School Kandy Combined Maths, Physics, Chemistry S K I L L S 2006 - 2019 Strong foundation in Statistics, Mathematics, Computer Science, and IT. Proficient in machine learning and deep learning techniques.\n",
      "2025-04-17 21:25:54,363 - INFO - Gemini raw response: [\"LSTM\", \"Streamlit\", \"Wix\", \"Python\", \"Machine Learning\", \"Scikit-learn\", \"TensorFlow\", \"OpenCV\", \"Excel\", \"SPSS\", \"R\", \"Minitab\", \"Power BI\", \"R Shiny\", \"NLTK\", \"Natural Language Toolkit\"]\n",
      "2025-04-17 21:25:54,365 - INFO - Cleaned Gemini response: [\"LSTM\", \"Streamlit\", \"Wix\", \"Python\", \"Machine Learning\", \"Scikit-learn\", \"TensorFlow\", \"OpenCV\", \"Excel\", \"SPSS\", \"R\", \"Minitab\", \"Power BI\", \"R Shiny\", \"NLTK\", \"Natural Language Toolkit\"]\n",
      "2025-04-17 21:25:54,367 - INFO - Extracted skills: ['LSTM', 'Streamlit', 'Wix', 'Python', 'Machine Learning', 'Scikit-learn', 'TensorFlow', 'OpenCV', 'Excel', 'SPSS', 'R', 'Minitab', 'Power BI', 'R Shiny', 'NLTK', 'Natural Language Toolkit']\n",
      "2025-04-17 21:25:55,087 - INFO - Gemini extracted experience: 0 years\n",
      "2025-04-17 21:25:57,024 - INFO - Gemini raw response for skill gap: [\"ETL\", \"A/B Testing\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:25:57,024 - INFO - Cleaned Gemini response for skill gap: [\"ETL\", \"A/B Testing\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:25:57,025 - INFO - Missing skills: ['ETL', 'A/B Testing', 'Data Visualization', 'Big Data']\n",
      "2025-04-17 21:25:57,025 - INFO - Processed Shashiprabha_Senanayake_Resume (3).pdf: Score = 1\n",
      "2025-04-17 21:25:57,026 - INFO - Ranked 3 CVs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked CVs:\n",
      "Rank 1: data-scientist-resume-example.pdf\n",
      "  Years of Experience: 7 (Weight: 1)\n",
      "  CV Skills: ['Python', 'NumPy', 'Pandas', 'Scikit-learn', 'Keras', 'Flask', 'SQL', 'MySQL', 'Postgres', 'Git', 'Time Series Forecasting', 'Productionizing Models', 'Recommendation Engines', 'AWS', 'Customer Segmentation', 'Cohort Analysis', 'Tableau', 'A/B Testing']\n",
      "  Missing Skills: ['ETL', 'Excel', 'Data Visualization', 'Big Data']\n",
      "  Skill Score: 2\n",
      "  Total Score: 3\n",
      "\n",
      "Rank 2: Nimantha_Kankanamge_Resume.pdf\n",
      "  Years of Experience: 1 (Weight: 1)\n",
      "  CV Skills: ['Statistical Analysis', 'R Studio', 'Teamwork', 'Collaboration', 'Data Analysis', 'Photography', 'Editing', 'Project Management', 'Environmental Science']\n",
      "  Missing Skills: ['ETL', 'Excel', 'A/B Testing', 'Data Visualization', 'Big Data']\n",
      "  Skill Score: 0\n",
      "  Total Score: 1\n",
      "\n",
      "Rank 3: Shashiprabha_Senanayake_Resume (3).pdf\n",
      "  Years of Experience: 0 (Weight: 0)\n",
      "  CV Skills: ['LSTM', 'Streamlit', 'Wix', 'Python', 'Machine Learning', 'Scikit-learn', 'TensorFlow', 'OpenCV', 'Excel', 'SPSS', 'R', 'Minitab', 'Power BI', 'R Shiny', 'NLTK', 'Natural Language Toolkit']\n",
      "  Missing Skills: ['ETL', 'A/B Testing', 'Data Visualization', 'Big Data']\n",
      "  Skill Score: 1\n",
      "  Total Score: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run CV Ranking\n",
    "cv_folder = r\"E:\\Individual Projects\\Skill_gap_system\\testcvs\"  # Adjust to your CV folder\n",
    "job_role = \"Data Scientist\"\n",
    "ranked_cvs = rank_cvs(cv_folder, job_role)\n",
    "print(\"Ranked CVs:\")\n",
    "for i, cv in enumerate(ranked_cvs, 1):\n",
    "    print(f\"Rank {i}: {cv['cv_file']}\")\n",
    "    print(f\"  Years of Experience: {cv['years_experience']} (Weight: {cv['experience_weight']})\")\n",
    "    print(f\"  CV Skills: {cv['cv_skills']}\")\n",
    "    print(f\"  Missing Skills: {cv['missing_skills']}\")\n",
    "    print(f\"  Skill Score: {cv['skill_score']}\")\n",
    "    print(f\"  Total Score: {cv['total_score']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf32d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de65359",
   "metadata": {},
   "outputs": [],
   "source": [
    "##______________________________(2)Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ebdcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "#%pip install pdfplumber pymongo google-generativeai dnspython pytesseract Pillow\n",
    "\n",
    "# Cell 2: Import Libraries and Setup\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Hardcode credentials\n",
    "GOOGLE_API_KEY = \"AIzaSyBvRnSojVCuojgtGI7RisnW6-S4VpBYJWo\"  # Your provided Gemini API key\n",
    "MONGODB_URI = \"mongodb+srv://shashi:VSXV9WDNmRvYnA7p@clusterskillgapanalysis.vnbcnju.mongodb.net/skillgapanalysis?retryWrites=true&w=majority\"\n",
    "\n",
    "# Import dependencies\n",
    "try:\n",
    "    import pdfplumber\n",
    "except ImportError:\n",
    "    raise ImportError(\"pdfplumber is not installed. Run: %pip install pdfplumber\")\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except ImportError:\n",
    "    raise ImportError(\"google-generativeai is not installed. Run: %pip install google-generativeai\")\n",
    "\n",
    "try:\n",
    "    import pytesseract\n",
    "    # Explicitly set Tesseract path (adjust if installed elsewhere)\n",
    "    pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "except ImportError:\n",
    "    raise ImportError(\"pytesseract or PIL is not installed. Run: %pip install pytesseract Pillow\")\n",
    "\n",
    "# Cell 3: MongoDB Connection\n",
    "def connect_to_mongodb():\n",
    "    try:\n",
    "        client = MongoClient(MONGODB_URI)\n",
    "        db = client[\"skillgapanalysis\"]\n",
    "        collection = db[\"jobrole_skill\"]\n",
    "        collection.create_index(\"Job_Role\")\n",
    "        logging.info(\"Connected to MongoDB Atlas\")\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to connect to MongoDB: {str(e)}\")\n",
    "        raise ValueError(f\"Failed to connect to MongoDB: {str(e)}\")\n",
    "\n",
    "# Cell 4: Enhanced CV Text Extraction\n",
    "def extract_cv_text(cv_path):\n",
    "    try:\n",
    "        with pdfplumber.open(cv_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\\n\"\n",
    "                    logging.info(f\"Extracted text from page {page.page_number} using pdfplumber\")\n",
    "                else:\n",
    "                    logging.warning(f\"No text extracted from page {page.page_number}. Using OCR.\")\n",
    "                    try:\n",
    "                        img = page.to_image().original\n",
    "                        ocr_text = pytesseract.image_to_string(img)\n",
    "                        text += ocr_text + \"\\n\\n\"\n",
    "                        logging.info(f\"Extracted OCR text from page {page.page_number}\")\n",
    "                    except Exception as ocr_e:\n",
    "                        logging.error(f\"OCR failed for page {page.page_number}: {str(ocr_e)}\")\n",
    "                        text += \"\\n\\n\"\n",
    "            if not text.strip():\n",
    "                raise ValueError(\"No text extracted from CV. Check PDF format or Tesseract installation.\")\n",
    "            logging.info(f\"Extracted text from CV: {text[:100]}...\")\n",
    "            return text\n",
    "    except pdfplumber.pdfminer.pdfdocument.PDFPasswordIncorrect:\n",
    "        logging.error(\"PDF is password-protected. Provide the password or use an unprotected PDF.\")\n",
    "        raise ValueError(\"PDF is password-protected\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading CV: {str(e)}\")\n",
    "        raise ValueError(f\"Error reading CV: {str(e)}\")\n",
    "\n",
    "# Cell 5: Skills Section Extraction\n",
    "def extract_skills_section(cv_text):\n",
    "    try:\n",
    "        match = re.search(\n",
    "            r\"(skills|technical skills|key skills|core competencies):?\\s*(.*?)(?=\\n\\s*(experience|education|projects|contact|certifications|references|$|\\n\\n))\",\n",
    "            cv_text, re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "        if match:\n",
    "            skills_text = match.group(2).strip()\n",
    "            skills_lines = [line.strip() for line in skills_text.split('\\n') if line.strip() and not re.match(r'^\\s*$', line)]\n",
    "            cleaned_skills = ' '.join(skills_lines).strip()\n",
    "            logging.info(f\"Extracted skills section: {cleaned_skills}\")\n",
    "            return cleaned_skills if cleaned_skills else cv_text\n",
    "        logging.warning(\"No explicit skills section found. Using full CV text for Gemini.\")\n",
    "        return cv_text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting skills section: {str(e)}\")\n",
    "        return cv_text\n",
    "\n",
    "# Cell 6: Gemini Skill Extraction\n",
    "def extract_skills_with_gemini(cv_text):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = (\n",
    "            \"You are an expert in CV analysis. Extract all skills from the following CV text, including: \"\n",
    "            \"1. Explicit skills listed in a 'Skills', 'Technical Skills', or similar section (e.g., 'Python, TensorFlow'). \"\n",
    "            \"2. Implicit skills inferred from 'Projects', 'Experience', or similar sections (e.g., 'Built a fraud detection model using scikit-learn' implies 'scikit-learn'). \"\n",
    "            \"Return a plain JSON array of clean, distinct skills (e.g., capitalize 'PyTorch', 'AWS SageMaker'). \"\n",
    "            \"Combine similar skills (e.g., 'ML' and 'Machine Learning' as 'Machine Learning'). \"\n",
    "            \"Return [] if no skills are found or input is empty. \"\n",
    "            \"Output must be a valid JSON array without ```json, backticks, or any other formatting. \"\n",
    "            \"Example: Input: 'Skills: Python, ML\\nProjects: Built a model using TensorFlow' \"\n",
    "            \"Output: [\\\"Python\\\", \\\"Machine Learning\\\", \\\"TensorFlow\\\"]\"\n",
    "            \"\\n\\nCV Text:\\n\" + cv_text\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        raw_response = response.text.strip()\n",
    "        logging.info(f\"Gemini raw response: {raw_response}\")\n",
    "        cleaned_response = raw_response\n",
    "        if cleaned_response.startswith(\"```json\\n\"):\n",
    "            cleaned_response = cleaned_response[8:].strip()\n",
    "        elif cleaned_response.startswith(\"```json\"):\n",
    "            cleaned_response = cleaned_response[7:].strip()\n",
    "        if cleaned_response.endswith(\"\\n```\"):\n",
    "            cleaned_response = cleaned_response[:-4].strip()\n",
    "        elif cleaned_response.endswith(\"```\"):\n",
    "            cleaned_response = cleaned_response[:-3].strip()\n",
    "        logging.info(f\"Cleaned Gemini response: {cleaned_response}\")\n",
    "        try:\n",
    "            skills = json.loads(cleaned_response)\n",
    "            if not isinstance(skills, list):\n",
    "                logging.error(\"Gemini response is not a JSON array\")\n",
    "                return []\n",
    "            logging.info(f\"Extracted skills: {skills}\")\n",
    "            return skills\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to parse cleaned Gemini response as JSON: {cleaned_response}, Error: {str(e)}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in Gemini skill extraction: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Cell 7: MongoDB Query\n",
    "def get_required_skills(job_collection, job_role):\n",
    "    try:\n",
    "        job_doc = job_collection.find_one({\"Job_Role\": job_role})\n",
    "        if not job_doc:\n",
    "            raise ValueError(f\"Job role '{job_role}' not found in database\")\n",
    "        required_skills = [skill.strip() for skill in job_doc[\"Required_Skills\"].split(\",\")]\n",
    "        logging.info(f\"Required skills for {job_role}: {required_skills}\")\n",
    "        return required_skills\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving required skills: {str(e)}\")\n",
    "        raise ValueError(f\"Error retrieving required skills: {str(e)}\")\n",
    "\n",
    "# Cell 8: Skill Gap Analysis with Gemini Semantic Similarity\n",
    "def skill_gap_analysis(cv_skills, required_skills):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = (\n",
    "            \"You are an expert in skill gap analysis. Given two lists of skills: \"\n",
    "            \"1. CV skills (from a candidate's CV). \"\n",
    "            \"2. Required skills (for a job role). \"\n",
    "            \"Identify which required skills are missing from the CV skills, considering semantic similarity and synonyms. \"\n",
    "            \"Treat skills as equivalent if they have the same or similar meaning (e.g., 'ML' ≈ 'Machine Learning', \"\n",
    "            \"'SQL' ≈ 'Database Management', 'Statistical Analysis' ≈ 'Statistics', 'Deep Learning' ≈ 'Neural Networks'). \"\n",
    "            \"Return a plain JSON array of the missing required skills, preserving their original names from the required skills list. \"\n",
    "            \"Output must be a valid JSON array without ```json or backticks. \"\n",
    "            \"Example: \"\n",
    "            \"CV skills: ['Python', 'SQL', 'Deep Learning'] \"\n",
    "            \"Required skills: ['Database Management', 'Neural Networks', 'Data Pipelines'] \"\n",
    "            \"Output: ['Data Pipelines'] \"\n",
    "            \"\\n\\nCV Skills:\\n\" + json.dumps(cv_skills) +\n",
    "            \"\\nRequired Skills:\\n\" + json.dumps(required_skills)\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        raw_response = response.text.strip()\n",
    "        logging.info(f\"Gemini raw response for skill gap: {raw_response}\")\n",
    "        cleaned_response = raw_response\n",
    "        if cleaned_response.startswith(\"```json\\n\"):\n",
    "            cleaned_response = cleaned_response[8:].strip()\n",
    "        elif cleaned_response.startswith(\"```json\"):\n",
    "            cleaned_response = cleaned_response[7:].strip()\n",
    "        if cleaned_response.endswith(\"\\n```\"):\n",
    "            cleaned_response = cleaned_response[:-4].strip()\n",
    "        elif cleaned_response.endswith(\"```\"):\n",
    "            cleaned_response = cleaned_response[:-3].strip()\n",
    "        logging.info(f\"Cleaned Gemini response for skill gap: {cleaned_response}\")\n",
    "        try:\n",
    "            missing_skills = json.loads(cleaned_response)\n",
    "            if not isinstance(missing_skills, list):\n",
    "                logging.error(\"Gemini response is not a JSON array\")\n",
    "                return []\n",
    "            logging.info(f\"Missing skills: {missing_skills}\")\n",
    "            return missing_skills\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to parse Gemini response: {cleaned_response}, Error: {str(e)}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in skill gap analysis: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Cell 9: Functions for Experience, Skill Weighting, and Ranking\n",
    "def extract_experience(cv_text):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = (\n",
    "            \"You are an expert in CV analysis. Extract the total years of professional experience from the following CV text by analyzing the 'Experience' or 'Work Experience' section. \"\n",
    "            \"Identify all job entries and their date ranges (e.g., 'March 2016 - June 2018'). \"\n",
    "            \"For each job, calculate the duration in months: (end_year - start_year)*12 + (end_month - start_month). \"\n",
    "            \"If the end date is 'Present', use April 2025 as the end date. \"\n",
    "            \"If a date is ambiguous (e.g., only year provided), assume January for start month and December for end month. \"\n",
    "            \"If a job has no clear date range, estimate 1 year if it seems like a short-term role (e.g., intern), else skip it. \"\n",
    "            \"Sum the durations of all jobs, convert to years (divide by 12, round to nearest integer), and return a single integer. \"\n",
    "            \"If no experience or dates are found, return 0. \"\n",
    "            \"Output only the integer, nothing else. \"\n",
    "            \"Example: \"\n",
    "            \"Input: 'Data Scientist, March 2016 - June 2018\\nAnalyst, April 2015 - March 2016' \"\n",
    "            \"Calculation: (2018-2016)*12 + (6-3) = 27 months; (2016-2015)*12 + (3-4) = 11 months; Total = 38/12 ≈ 3 years \"\n",
    "            \"Output: 3 \"\n",
    "            \"\\n\\nCV Text:\\n\" + cv_text\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        years = int(response.text.strip())\n",
    "        logging.info(f\"Gemini extracted experience: {years} years\")\n",
    "        return years\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting experience: {str(e)}\")\n",
    "        return 0\n",
    "\n",
    "def assign_experience_weight(years):\n",
    "    if years > 15:\n",
    "        return 3  # High\n",
    "    elif 8 <= years <= 15:\n",
    "        return 2  # Medium\n",
    "    elif 1 <= years <= 7:\n",
    "        return 1  # Low\n",
    "    return 0  # None or <1 year\n",
    "\n",
    "def assign_skill_weights(job_role, required_skills):\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        num_skills = len(required_skills)\n",
    "        prompt = (\n",
    "            f\"You are an expert in recruitment for the job role '{job_role}'. \"\n",
    "            f\"Given the following required skills: {json.dumps(required_skills)}, \"\n",
    "            f\"assign a weight to each skill based on its relevance to the job role. \"\n",
    "            f\"Use integers from 1 (least relevant) to {num_skills} (most relevant), ensuring each skill gets a unique weight. \"\n",
    "            \"Consider technical skills (e.g., 'Python' for Data Scientist) as more relevant than soft or unrelated skills (e.g., 'Hiking'). \"\n",
    "            \"Return a JSON object mapping each skill to its weight. \"\n",
    "            \"Output must be a valid JSON object without ```json or backticks. \"\n",
    "            \"Example: \"\n",
    "            \"Job role: Data Scientist \"\n",
    "            \"Required skills: ['Python', 'Report Writing', 'Hiking'] \"\n",
    "            \"Output: {\\\"Python\\\": 3, \\\"Report Writing\\\": 2, \\\"Hiking\\\": 1}\"\n",
    "            \"\\n\\nRequired Skills:\\n\" + json.dumps(required_skills)\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        raw_response = response.text.strip()\n",
    "        logging.info(f\"Gemini raw response for skill weights: {raw_response}\")\n",
    "        cleaned_response = raw_response\n",
    "        if cleaned_response.startswith(\"```json\\n\"):\n",
    "            cleaned_response = cleaned_response[8:].strip()\n",
    "        elif cleaned_response.startswith(\"```json\"):\n",
    "            cleaned_response = cleaned_response[7:].strip()\n",
    "        if cleaned_response.endswith(\"\\n```\"):\n",
    "            cleaned_response = cleaned_response[:-4].strip()\n",
    "        elif cleaned_response.endswith(\"```\"):\n",
    "            cleaned_response = cleaned_response[:-3].strip()\n",
    "        logging.info(f\"Cleaned Gemini response for skill weights: {cleaned_response}\")\n",
    "        try:\n",
    "            weights = json.loads(cleaned_response)\n",
    "            if not isinstance(weights, dict):\n",
    "                logging.error(\"Gemini response is not a JSON object\")\n",
    "                return {skill: 1 for skill in required_skills}  # Fallback: equal weights\n",
    "            logging.info(f\"Skill weights: {weights}\")\n",
    "            return weights\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to parse Gemini response: {cleaned_response}, Error: {str(e)}\")\n",
    "            return {skill: 1 for skill in required_skills}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error assigning skill weights: {str(e)}\")\n",
    "        return {skill: 1 for skill in required_skills}\n",
    "\n",
    "def rank_cvs(cv_folder, job_role):\n",
    "    try:\n",
    "        job_collection = connect_to_mongodb()\n",
    "        required_skills = get_required_skills(job_collection, job_role)\n",
    "        skill_weights = assign_skill_weights(job_role, required_skills)\n",
    "        cv_results = []\n",
    "\n",
    "        for cv_file in os.listdir(cv_folder):\n",
    "            if cv_file.lower().endswith('.pdf'):\n",
    "                cv_path = os.path.join(cv_folder, cv_file)\n",
    "                try:\n",
    "                    cv_text = extract_cv_text(cv_path)\n",
    "                    skills_text = extract_skills_section(cv_text)\n",
    "                    cv_skills = extract_skills_with_gemini(skills_text)\n",
    "                    if not cv_skills:\n",
    "                        logging.warning(f\"No skills extracted from {cv_file}\")\n",
    "                        continue\n",
    "\n",
    "                    years = extract_experience(cv_text)\n",
    "                    exp_weight = assign_experience_weight(years)\n",
    "                    missing_skills = skill_gap_analysis(cv_skills, required_skills)\n",
    "                    skill_score = sum(skill_weights.get(skill, 0) for skill in cv_skills if skill in required_skills)\n",
    "                    total_score = exp_weight + skill_score\n",
    "\n",
    "                    cv_results.append({\n",
    "                        \"cv_file\": cv_file,\n",
    "                        \"years_experience\": years,\n",
    "                        \"experience_weight\": exp_weight,\n",
    "                        \"cv_skills\": cv_skills,\n",
    "                        \"required_skills\": required_skills,\n",
    "                        \"missing_skills\": missing_skills,\n",
    "                        \"skill_score\": skill_score,\n",
    "                        \"total_score\": total_score\n",
    "                    })\n",
    "                    logging.info(f\"Processed {cv_file}: Score = {total_score}\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing {cv_file}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "        ranked_cvs = sorted(cv_results, key=lambda x: x[\"total_score\"], reverse=True)\n",
    "        logging.info(f\"Ranked {len(ranked_cvs)} CVs\")\n",
    "        return ranked_cvs\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in CV ranking: {str(e)}\")\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bddb057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 21:39:47,848 - INFO - Connected to MongoDB Atlas\n",
      "2025-04-17 21:39:48,155 - INFO - Required skills for Data Scientist: ['ETL', 'Excel', 'A/B Testing', 'Data Visualization', 'Big Data']\n",
      "2025-04-17 21:39:49,383 - INFO - Gemini raw response for skill weights: {\n",
      "  \"Big Data\": 5,\n",
      "  \"ETL\": 4,\n",
      "  \"Data Visualization\": 3,\n",
      "  \"A/B Testing\": 2,\n",
      "  \"Excel\": 1\n",
      "}\n",
      "2025-04-17 21:39:49,384 - INFO - Cleaned Gemini response for skill weights: {\n",
      "  \"Big Data\": 5,\n",
      "  \"ETL\": 4,\n",
      "  \"Data Visualization\": 3,\n",
      "  \"A/B Testing\": 2,\n",
      "  \"Excel\": 1\n",
      "}\n",
      "2025-04-17 21:39:49,385 - INFO - Skill weights: {'Big Data': 5, 'ETL': 4, 'Data Visualization': 3, 'A/B Testing': 2, 'Excel': 1}\n",
      "2025-04-17 21:39:49,389 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:39:49,662 - INFO - Extracted text from page 1 using pdfplumber\n",
      "2025-04-17 21:39:49,663 - INFO - Extracted text from CV: K A N DA C E L O U D O R\n",
      "DATA SCIENTIST\n",
      "CONTACT WORK EXPERIENCE\n",
      "kloudor@email.com Data Scientist\n",
      "(12...\n",
      "2025-04-17 21:39:49,664 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:39:49,665 - INFO - Extracted skills section: Spectrix Analytical Services March 2016 - June 2018 / Princeton, NJ Python (NumPy, Pandas, Built a customer attrition random forest model that improved Scikit-learn, Keras, Flask) monthly retention by 12 basis points for clients likely to opt-out SQL (MySQL, Postgres) by providing relevant product features for them Git Coordinated with the product and marketing teams to determine Time Series Forecasting what kind of client interactions resulted in maximized service Productionizing Models opt-ins, increasing conversions by 18% Recommendation Engines Partnered with product team to create a production Customer Segmentation recommendation engine in Python that improved the length on- AWS page for users with $225K in incremental annual revenue Compiled and analyzed data surrounding the prototypes for a prosthesis, which saved over $1M in its creation Entry-Level Data Analyst Avenica April 2015 - March 2016 / Mount Laurel, NJ Collaborated with product managers to perform cohort analysis that identified an opportunity to reduce pricing by 21% for a segment of users to boost yearly revenue by $560,000 Constructed operational reporting in Tableau to improve scheduling contractors, saving $90,000 in the annual budget Implemented a long-term pricing experiment that improved customer lifetime value by 23% Ran, submitted, and reported on monthly client enrollments, services opted in for, and the employees assigned to clients\n",
      "2025-04-17 21:39:51,023 - INFO - Gemini raw response: [\"Python\", \"NumPy\", \"Pandas\", \"Scikit-learn\", \"Keras\", \"Flask\", \"SQL\", \"MySQL\", \"Postgres\", \"Git\", \"Time Series Forecasting\", \"Productionizing Models\", \"Recommendation Engines\", \"AWS\", \"Tableau\", \"Cohort Analysis\", \"A/B Testing\", \"Pricing Experiments\", \"Customer Lifetime Value\", \"Data Analysis\", \"Random Forest\", \"Customer Segmentation\"]\n",
      "2025-04-17 21:39:51,024 - INFO - Cleaned Gemini response: [\"Python\", \"NumPy\", \"Pandas\", \"Scikit-learn\", \"Keras\", \"Flask\", \"SQL\", \"MySQL\", \"Postgres\", \"Git\", \"Time Series Forecasting\", \"Productionizing Models\", \"Recommendation Engines\", \"AWS\", \"Tableau\", \"Cohort Analysis\", \"A/B Testing\", \"Pricing Experiments\", \"Customer Lifetime Value\", \"Data Analysis\", \"Random Forest\", \"Customer Segmentation\"]\n",
      "2025-04-17 21:39:51,025 - INFO - Extracted skills: ['Python', 'NumPy', 'Pandas', 'Scikit-learn', 'Keras', 'Flask', 'SQL', 'MySQL', 'Postgres', 'Git', 'Time Series Forecasting', 'Productionizing Models', 'Recommendation Engines', 'AWS', 'Tableau', 'Cohort Analysis', 'A/B Testing', 'Pricing Experiments', 'Customer Lifetime Value', 'Data Analysis', 'Random Forest', 'Customer Segmentation']\n",
      "2025-04-17 21:39:52,047 - INFO - Gemini extracted experience: 4 years\n",
      "2025-04-17 21:39:53,992 - INFO - Gemini raw response for skill gap: [\"ETL\", \"Excel\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:39:53,993 - INFO - Cleaned Gemini response for skill gap: [\"ETL\", \"Excel\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:39:53,994 - INFO - Missing skills: ['ETL', 'Excel', 'Data Visualization', 'Big Data']\n",
      "2025-04-17 21:39:53,995 - INFO - Processed data-scientist-resume-example.pdf: Score = 3\n",
      "2025-04-17 21:39:53,999 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:39:54,000 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:39:54,203 - INFO - Extracted text from page 1 using pdfplumber\n",
      "2025-04-17 21:39:54,372 - INFO - Extracted text from page 2 using pdfplumber\n",
      "2025-04-17 21:39:54,374 - INFO - Extracted text from CV: Nimantha Kankanamge\n",
      "nimanthak0718@gmail.com 0767664176\n",
      "Kandy, Sri Lanka 18/07/1999 Male\n",
      "nimantha-kan...\n",
      "2025-04-17 21:39:54,375 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:39:54,376 - WARNING - CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-17 21:39:54,378 - INFO - Extracted skills section: Water quality testing and chemical Statistical Analysis Using R Studio experiments Teamwork and Collaboration Data Analysis Photography and Editing Project Management Organizations Environmental Science Society- University of Peradeniya, 2023 – 2024 Committee Member perabeats Media Society-University of Peradeniya, Junior Treasurer 2023 – 2024 Managed the budget throughout the year while coordinating projects within the society. perabeats Media Society - University of Peradeniya, Senior Coordinator 2022 – 2023 Coordinate photographers, Editing and publishing photographs while managing the society’s page. Also worked as a photographer and editor.\n",
      "2025-04-17 21:39:55,426 - INFO - Gemini raw response: [\"Statistical Analysis\", \"R Studio\", \"Teamwork\", \"Collaboration\", \"Data Analysis\", \"Photography\", \"Editing\", \"Project Management\", \"Environmental Science\"]\n",
      "2025-04-17 21:39:55,428 - INFO - Cleaned Gemini response: [\"Statistical Analysis\", \"R Studio\", \"Teamwork\", \"Collaboration\", \"Data Analysis\", \"Photography\", \"Editing\", \"Project Management\", \"Environmental Science\"]\n",
      "2025-04-17 21:39:55,429 - INFO - Extracted skills: ['Statistical Analysis', 'R Studio', 'Teamwork', 'Collaboration', 'Data Analysis', 'Photography', 'Editing', 'Project Management', 'Environmental Science']\n",
      "2025-04-17 21:39:56,348 - INFO - Gemini extracted experience: 1 years\n",
      "2025-04-17 21:39:57,347 - INFO - Gemini raw response for skill gap: [\"ETL\", \"Excel\", \"A/B Testing\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:39:57,348 - INFO - Cleaned Gemini response for skill gap: [\"ETL\", \"Excel\", \"A/B Testing\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:39:57,348 - INFO - Missing skills: ['ETL', 'Excel', 'A/B Testing', 'Data Visualization', 'Big Data']\n",
      "2025-04-17 21:39:57,349 - INFO - Processed Nimantha_Kankanamge_Resume.pdf: Score = 1\n",
      "2025-04-17 21:39:57,655 - INFO - Extracted text from page 1 using pdfplumber\n",
      "2025-04-17 21:39:57,656 - INFO - Extracted text from CV: SHASHIPRABHA\n",
      "SENANAYAKE\n",
      "Data Science Research Intern working on AI modelling with\n",
      "a strong passion f...\n",
      "2025-04-17 21:39:57,657 - INFO - Extracted skills section: and grow in a dynamic environment. C O N T A C T P R O J E C T S AI powered skill gap analysis system (Ongoing) +94 70 5523737 LSTM model to predict dissolved oxygen levels in ponds in Myanmar, deployed shashiprabhasenanayake@gmail.com via Streamlit and integrated with Wix. - Final year research Customer churn prediction for landline telephone services - Python shashiprabha-senanayake Machine learning model to detect fraud in online payments – Python (scikit-learn) shashiprabha-senanayake Convolutional neural network to detect cracks on the concrete surface, [IBM AI engineering capstone project] – Python (TensorFlow, OpenCV) Regression model to predict the productivity of employees in garment E D U C A T I O N manufacturing companies– Python(scikit-learn) Twitter sentiment analysis - Python (scikit-learn, NLTK(natural language toolkit) Data analysis on the Impact of undergraduate preferences on Sri Lankan job University of Colombo market - Python, Excel, SPSS, R and Minitab Interactive dashboard to visualize global YouTube statistics for 2023 - PowerBI BSc(Hons) Applied Statistics Interactive dashboard to present electric vehicle population data - R shiny 2021 - 2025 Analyse the reasons for the customer complaints on their internet connection issues - SPSS, Excel Girls’ High School Kandy Combined Maths, Physics, Chemistry S K I L L S 2006 - 2019 Strong foundation in Statistics, Mathematics, Computer Science, and IT. Proficient in machine learning and deep learning techniques.\n",
      "2025-04-17 21:39:59,112 - INFO - Gemini raw response: [\"LSTM\", \"Streamlit\", \"Wix\", \"Python\", \"scikit-learn\", \"TensorFlow\", \"OpenCV\", \"Machine Learning\", \"Deep Learning\", \"Power BI\", \"R\", \"R Shiny\", \"SPSS\", \"Excel\", \"NLTK\", \"Natural Language Toolkit\", \"Data Analysis\", \"Statistics\", \"Mathematics\", \"Computer Science\", \"IT\"]\n",
      "2025-04-17 21:39:59,113 - INFO - Cleaned Gemini response: [\"LSTM\", \"Streamlit\", \"Wix\", \"Python\", \"scikit-learn\", \"TensorFlow\", \"OpenCV\", \"Machine Learning\", \"Deep Learning\", \"Power BI\", \"R\", \"R Shiny\", \"SPSS\", \"Excel\", \"NLTK\", \"Natural Language Toolkit\", \"Data Analysis\", \"Statistics\", \"Mathematics\", \"Computer Science\", \"IT\"]\n",
      "2025-04-17 21:39:59,114 - INFO - Extracted skills: ['LSTM', 'Streamlit', 'Wix', 'Python', 'scikit-learn', 'TensorFlow', 'OpenCV', 'Machine Learning', 'Deep Learning', 'Power BI', 'R', 'R Shiny', 'SPSS', 'Excel', 'NLTK', 'Natural Language Toolkit', 'Data Analysis', 'Statistics', 'Mathematics', 'Computer Science', 'IT']\n",
      "2025-04-17 21:40:00,033 - INFO - Gemini extracted experience: 1 years\n",
      "2025-04-17 21:40:00,955 - INFO - Gemini raw response for skill gap: [\"ETL\", \"A/B Testing\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:40:00,957 - INFO - Cleaned Gemini response for skill gap: [\"ETL\", \"A/B Testing\", \"Data Visualization\", \"Big Data\"]\n",
      "2025-04-17 21:40:00,957 - INFO - Missing skills: ['ETL', 'A/B Testing', 'Data Visualization', 'Big Data']\n",
      "2025-04-17 21:40:00,958 - INFO - Processed Shashiprabha_Senanayake_Resume (3).pdf: Score = 2\n",
      "2025-04-17 21:40:00,960 - INFO - Ranked 3 CVs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked CVs:\n",
      "Rank 1: data-scientist-resume-example.pdf\n",
      "  Years of Experience: 4 (Weight: 1)\n",
      "  CV Skills: ['Python', 'NumPy', 'Pandas', 'Scikit-learn', 'Keras', 'Flask', 'SQL', 'MySQL', 'Postgres', 'Git', 'Time Series Forecasting', 'Productionizing Models', 'Recommendation Engines', 'AWS', 'Tableau', 'Cohort Analysis', 'A/B Testing', 'Pricing Experiments', 'Customer Lifetime Value', 'Data Analysis', 'Random Forest', 'Customer Segmentation']\n",
      "  Missing Skills: ['ETL', 'Excel', 'Data Visualization', 'Big Data']\n",
      "  Skill Score: 2\n",
      "  Total Score: 3\n",
      "\n",
      "Rank 2: Shashiprabha_Senanayake_Resume (3).pdf\n",
      "  Years of Experience: 1 (Weight: 1)\n",
      "  CV Skills: ['LSTM', 'Streamlit', 'Wix', 'Python', 'scikit-learn', 'TensorFlow', 'OpenCV', 'Machine Learning', 'Deep Learning', 'Power BI', 'R', 'R Shiny', 'SPSS', 'Excel', 'NLTK', 'Natural Language Toolkit', 'Data Analysis', 'Statistics', 'Mathematics', 'Computer Science', 'IT']\n",
      "  Missing Skills: ['ETL', 'A/B Testing', 'Data Visualization', 'Big Data']\n",
      "  Skill Score: 1\n",
      "  Total Score: 2\n",
      "\n",
      "Rank 3: Nimantha_Kankanamge_Resume.pdf\n",
      "  Years of Experience: 1 (Weight: 1)\n",
      "  CV Skills: ['Statistical Analysis', 'R Studio', 'Teamwork', 'Collaboration', 'Data Analysis', 'Photography', 'Editing', 'Project Management', 'Environmental Science']\n",
      "  Missing Skills: ['ETL', 'Excel', 'A/B Testing', 'Data Visualization', 'Big Data']\n",
      "  Skill Score: 0\n",
      "  Total Score: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run CV Ranking\n",
    "cv_folder = r\"E:\\Individual Projects\\Skill_gap_system\\testcvs\"  # Adjust to your CV folder\n",
    "job_role = \"Data Scientist\"\n",
    "ranked_cvs = rank_cvs(cv_folder, job_role)\n",
    "print(\"Ranked CVs:\")\n",
    "for i, cv in enumerate(ranked_cvs, 1):\n",
    "    print(f\"Rank {i}: {cv['cv_file']}\")\n",
    "    print(f\"  Years of Experience: {cv['years_experience']} (Weight: {cv['experience_weight']})\")\n",
    "    print(f\"  CV Skills: {cv['cv_skills']}\")\n",
    "    print(f\"  Missing Skills: {cv['missing_skills']}\")\n",
    "    print(f\"  Skill Score: {cv['skill_score']}\")\n",
    "    print(f\"  Total Score: {cv['total_score']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
